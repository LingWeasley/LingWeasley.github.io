<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black"><link rel="icon" href="/images/icons/favicon-16x16.png?v=2.8.0" type="image/png" sizes="16x16"><link rel="icon" href="/images/icons/favicon-32x32.png?v=2.8.0" type="image/png" sizes="32x32"><meta property="og:type" content="website">
<meta property="og:title" content="漏勺的加油站">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="漏勺的加油站">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="小勺">
<meta name="twitter:card" content="summary"><title>漏勺的加油站</title><link ref="canonical" href="http://example.com/index.html"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.12.1/css/all.min.css" type="text/css"><link rel="stylesheet" href="/css/index.css?v=2.8.0"><link rel="stylesheet" href="css/custom.css"><script>var Stun = window.Stun || {};
var CONFIG = {
  root: '/',
  algolia: undefined,
  assistSearch: undefined,
  fontIcon: {"prompt":{"success":"fas fa-check-circle","info":"fas fa-arrow-circle-right","warning":"fas fa-exclamation-circle","error":"fas fa-times-circle"},"copyBtn":"fas fa-copy"},
  sidebar: {"offsetTop":"20px","tocMaxDepth":6},
  header: {"enable":true,"showOnPost":true,"scrollDownIcon":false},
  postWidget: {"endText":true},
  nightMode: {"enable":true},
  back2top: {"enable":true},
  codeblock: {"style":"default","highlight":"light","wordWrap":false},
  reward: false,
  fancybox: false,
  zoomImage: {"gapAside":"20px"},
  galleryWaterfall: undefined,
  lazyload: false,
  pjax: undefined,
  externalLink: {"icon":{"enable":true,"name":"fas fa-external-link-alt"}},
  shortcuts: undefined,
  prompt: {"copyButton":"复制","copySuccess":"复制成功","copyError":"复制失败"},
  sourcePath: {"js":"js","css":"css","images":"images"},
};

window.CONFIG = CONFIG;</script><meta name="generator" content="Hexo 6.0.0"></head><body><div class="container" id="container"><header class="header" id="header"><div class="header-inner"><nav class="header-nav header-nav--fixed"><div class="header-nav-inner"><div class="header-nav-menubtn"><i class="fas fa-bars"></i></div><div class="header-nav-menu"><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/"><span class="header-nav-menu-item__icon"><i class="fas fa-home"></i></span><span class="header-nav-menu-item__text">首页</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/archives/"><span class="header-nav-menu-item__icon"><i class="fas fa-folder-open"></i></span><span class="header-nav-menu-item__text">归档</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/categories/"><span class="header-nav-menu-item__icon"><i class="fas fa-layer-group"></i></span><span class="header-nav-menu-item__text">分类</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/tags/"><span class="header-nav-menu-item__icon"><i class="fas fa-tags"></i></span><span class="header-nav-menu-item__text">标签</span></a></div></div><div class="header-nav-mode"><div class="mode"><div class="mode-track"><span class="mode-track-moon"></span><span class="mode-track-sun"></span></div><div class="mode-thumb"></div></div></div></div></nav><div class="header-banner"></div></div></header><main class="main" id="main"><div class="main-inner"><div class="content-wrap" id="content-wrap"><div class="content content-home" id="content"><section class="postlist"><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/2023/06/20/%E8%87%AA%E5%8A%A8%E6%B1%82%E5%AF%BC/">自动求导</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">发表于</span><span class="post-meta-item__value">2023-06-20</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">更新于</span><span class="post-meta-item__value">2023-06-20</span></span></div></header><div class="post-body"><div class="post-excerpt">
        <h1 id="自动求导"   >
          <a href="#自动求导" class="heading-link"><i class="fas fa-link"></i></a><a href="#自动求导" class="headerlink" title="自动求导"></a>自动求导</h1>
      <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">x = torch.arange(<span class="number">4.0</span>)  <span class="comment"># 关于列向量x求导，创建一个x四维向量</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 在我们计算y关于x的梯度之前，我们需要一个地方来存储梯度</span></span><br><span class="line">x.requires_grad_(<span class="literal">True</span>) <span class="comment"># 等价与x = torch.arange(4.0,requires_grad=True)</span></span><br><span class="line">x.grad <span class="comment"># 默认值是none</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算y</span></span><br><span class="line">y = <span class="number">2</span> * torch.dot(x, x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过调用反向传播函数来自动计算y关于x每个分量的梯度</span></span><br><span class="line">y.backward() <span class="comment">#求导</span></span><br><span class="line">x.grad <span class="comment">#访问导数</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 在默认情况下，pytorch会累积梯度，我们需要清楚之前的值</span></span><br><span class="line">x.grad.zero_() <span class="comment"># 下划线表示重写内容</span></span><br><span class="line">y = x.<span class="built_in">sum</span>()</span><br><span class="line">y.backward()</span><br><span class="line">x.grad</span><br><span class="line"></span><br><span class="line"><span class="comment"># 深度学习中，我们的目的不是计算微分矩阵，而是批量中每个样本单独计算的偏导数之和</span></span><br><span class="line"><span class="comment"># 对非标量调用backward需要传入一个gradient参数，该参数指定微分函数,一般情况下只对标量求导，如果非标量就要求和先转换成标量</span></span><br><span class="line">x.gead.zero_()</span><br><span class="line">y = x * x</span><br><span class="line"><span class="comment"># 等价于y.backward(torch.ones(len(x)))</span></span><br><span class="line">y.<span class="built_in">sum</span>().backwad()</span><br><span class="line">x.grad</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将某些计算移动到记录的计算图之外</span></span><br><span class="line">x.grad.zero_() <span class="comment"># 清理梯度</span></span><br><span class="line">y = x * x</span><br><span class="line">u = y.detach() <span class="comment">#y是一个函数，detach将y变为一个常数</span></span><br><span class="line">z = u * x</span><br><span class="line"></span><br><span class="line">z.<span class="built_in">sum</span>().backward()</span><br><span class="line">x.grad == u  <span class="comment">#验证求导结果？</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#或者</span></span><br><span class="line">x.grad.zero_()</span><br><span class="line">y.<span class="built_in">sum</span>().backward()</span><br><span class="line">x.grad == <span class="number">2</span> * x</span><br><span class="line"></span><br><span class="line"><span class="comment">#即使构建函数的计算图需要通过python控制流（例如，条件，循环或任意函数调用），我们仍然可以计算到的变量的梯度</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">f</span>(<span class="params">a</span>):</span><br><span class="line">    b = a * <span class="number">2</span></span><br><span class="line">    <span class="keyword">while</span> b.norm() &lt; <span class="number">1000</span>:</span><br><span class="line">        b = n * <span class="number">2</span></span><br><span class="line">    <span class="keyword">if</span> b.<span class="built_in">sum</span>() &gt; <span class="number">0</span>:</span><br><span class="line">        c = b</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        c = <span class="number">100</span> * b</span><br><span class="line">    <span class="keyword">return</span> c</span><br><span class="line"></span><br><span class="line">a = torch.randn(size=(),requires_grad=<span class="literal">True</span>)</span><br><span class="line">d = f(a)</span><br><span class="line">d.backward()</span><br><span class="line"></span><br><span class="line">a.grad == d / a</span><br><span class="line"></span><br></pre></td></tr></table></div></figure></div></div></article><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/2023/06/18/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/">线性代数</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">发表于</span><span class="post-meta-item__value">2023-06-18</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">更新于</span><span class="post-meta-item__value">2023-06-20</span></span></div></header><div class="post-body"><div class="post-excerpt"><figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建一个矩阵</span></span><br><span class="line">A = torch.arange(<span class="number">20</span>).reshape(<span class="number">5</span>, <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 矩阵的转置</span></span><br><span class="line">A.T</span><br><span class="line"></span><br><span class="line"><span class="comment"># 给定具有相同形状的任何两个张量，任何按元素二元运算呢的结果都将是相同形状的张量</span></span><br><span class="line">A = torch.arange(<span class="number">20</span>, dtype=torch.float32).reshape(<span class="number">5</span>, <span class="number">4</span>)</span><br><span class="line">B = A.clone() <span class="comment">#通过分配新内存，将A的一个副本分配给B</span></span><br><span class="line">A, A + B</span><br><span class="line"></span><br><span class="line">&lt;!--more--&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 两个矩阵的按元素乘法成为 哈达玛吉 （hadamard product）数学符号圈点</span></span><br><span class="line"></span><br><span class="line">A * B</span><br><span class="line"></span><br><span class="line">a = <span class="number">2</span></span><br><span class="line">X = torch.arange(<span class="number">24</span>).reshape(<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line">a + X, (a * X).shape</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算元素的和</span></span><br><span class="line">X = torch.arange(<span class="number">4</span>, dtype=torch.float32)</span><br><span class="line">x, x.<span class="built_in">sum</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 表示任意形状张量的元素和</span></span><br><span class="line">A.shape, A.<span class="built_in">sum</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 指定求和汇总张量的轴 shape二维行为0 ，列为1</span></span><br><span class="line">A_sum_axis0 = A.<span class="built_in">sum</span>(axis=<span class="number">0</span>)</span><br><span class="line">A_sum_axis0, A_sum_axis0.shape</span><br><span class="line"></span><br><span class="line">A_sum_axis1 = A.<span class="built_in">sum</span>(axis=<span class="number">1</span>)</span><br><span class="line">A_sum_axis1, A_sum_axis1.shape</span><br><span class="line"></span><br><span class="line">A.<span class="built_in">sum</span>(axis=[<span class="number">0</span>,<span class="number">1</span>]).shape </span><br><span class="line"></span><br><span class="line"><span class="comment"># 一个与求和相关的量是平均值（mean或average）</span></span><br><span class="line">A.mean(), A.<span class="built_in">sum</span>()/A.numel()</span><br><span class="line"></span><br><span class="line">A.mean(axis=<span class="number">0</span>), A.<span class="built_in">sum</span>(axis=<span class="number">0</span>)/A.numel(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算总和或均值时保持轴数不变</span></span><br><span class="line"></span><br><span class="line">sum_A = A.<span class="built_in">sum</span>(axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过广播将A除以sum_A</span></span><br><span class="line">A  / sum_A</span><br><span class="line"></span><br><span class="line"><span class="comment"># 某个轴计算A元素的累积总和</span></span><br><span class="line">A.cumsum(axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 点积是相同位置的按元素乘积的和</span></span><br><span class="line"></span><br><span class="line">Y = torch,ones(<span class="number">4</span>, dtype=torch.float32)</span><br><span class="line">x,y torch.dot(x, y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 我们可以通过执行按元素乘法，然后进行求和来表示两个向量的点积</span></span><br><span class="line"></span><br><span class="line">torch.<span class="built_in">sum</span>(x * y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 矩阵向量积Ax是一个长度为m的列向量，其ith元素是点积atix</span></span><br><span class="line">A.shape, x.shape, torch.mv(A, x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 我们可以将矩阵-矩阵乘法AB看作是简单地执行m次矩阵-向量积，并将结果拼接在一起，形成一个n*m矩阵</span></span><br><span class="line">B = torch.ones(<span class="number">4</span>, <span class="number">3</span>)</span><br><span class="line">torch.mm(A, B)</span><br><span class="line"></span><br><span class="line"><span class="comment"># L2范数是向量元素平方和的平方根： 向量或者矩阵的长度</span></span><br><span class="line"></span><br><span class="line">u = torch.tensor([<span class="number">3.0</span>, -<span class="number">4.0</span>]) <span class="comment">#u 为向量</span></span><br><span class="line">torch.norm(u)</span><br><span class="line"></span><br><span class="line"><span class="comment"># L1范数，它表示为向量元素的绝对值之和：</span></span><br><span class="line"></span><br><span class="line">torch.<span class="built_in">abs</span>(u).<span class="built_in">sum</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 矩阵的佛罗贝尼乌斯范数（Frobenius norm）是矩阵元素的平发放和的平方根</span></span><br><span class="line">torch.norm(torch.ones((<span class="number">4</span>, <span class="number">9</span>)))</span><br></pre></td></tr></table></div></figure></div></div></article><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/2023/02/15/Prototypical%20Networks%20for%20Few-shot%20Learning/">Prototypical Networks for Few-shot Learning</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">发表于</span><span class="post-meta-item__value">2023-02-15</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">更新于</span><span class="post-meta-item__value">2023-06-18</span></span></div></header><div class="post-body"><div class="post-excerpt"><p>1.原型网络的思想：将每个类别中的样例数据映射到一个空间当中，并且提取他们的“均值”来表示为该类的原型（prototype）。使用欧几里得距离作为距离度量，训练使得本类别数据到本类原形表示的距离为最近，到其他类原形表示的距离较远。测试时，对测试数据到各个类别的原形数据的距离做softmax，来判断测试数据的类别标签。<br>2.模型<br>原形网络要为每个类别计算出一个原形表示Ck，通过一个embedding函数将维度D的样例数据映射到M维的空间上。类别的原形表示Ck是对支持集中的所有的向量化样例数据取均值得到的。在测试时，原形网络使用softmax作用在query向量点到Ck的距离。训练过程是通过随机梯度下降法最小化目标函数<br>3。下面它的伪代码<br>（1）从一个大的数据集上随机采样一个N-Way K-shot任务，为一个episode</p>
<p>（2）将这个episode分为支持集、<span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E8%AF%A2%E9%97%AE%E9%9B%86&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22article%22,%22sourceId%22:%22268824689%22%7D" >询问集</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></p>
<p>（3）根据支持集按照均值计算prototypes</p>
<p>（4）按照类别顺序，利用所有类别询问集中的数据计算<span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22article%22,%22sourceId%22:%22268824689%22%7D" >损失函数</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></p>
<p>（5）不断抽取不同的episode，按照（1）（2）（3）（4）循环</p>
<ol start="4">
<li>数据集-采用</li>
<li>在数据集上的结果–看实验结果可以发现，原型网络在Omniglot数据集上的表现，超过其他网络。<br>在miniImageNet上做了更多的比较，并进行了欧几里得距离和余弦相似度两种方法的比较，可以看出在原型网络和匹配网络上欧几里得距离都表现的更好。</li>
</ol>
</div></div></article><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/2023/02/10/%E5%AD%97%E8%8A%82%E8%B7%B3%E5%8A%A8/">SEGMENT-LEVEL METRIC LEARNING FOR FEW-SHOT BIOACOUSTIC EVENT DETECTION</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">发表于</span><span class="post-meta-item__value">2023-02-10</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">更新于</span><span class="post-meta-item__value">2023-06-18</span></span></div></header><div class="post-body"><div class="post-excerpt"><p>小样本生物声学事件检测是一项检测给定几个例子的新声音的发生时间的任务。以前的方法采用度量学习，用不同声音类别的标记部分建立一个潜在的空间，也就是所谓的正面事件。在这项研究中，我们提出了一个段级的小样本学习框架，在模型优化过程中同时利用正面和负面事件。用负面事件进行训练，其数量比正面事件大，可以提高模型的泛化能力。此外，在训练过程中，我们在验证集上使用过渡性推理，以更好地适应新的类别。我们通过对输入特征、训练数据和超参数的不同设置对我们提出的方法进行了消融研究。我们最终的系统在DCASE2022挑战任务5（DCASE2022-T5）验证集上取得了62.73的F值，比基线原型网络34.02的性能要好得多。使用建议的方法，我们提交的系统在DCASE2022-T5中排名第二。本文的代码是完全开放的1</p>
<p>小样本学习（FSL）[1]是一个机器学习问题，根据包含有限信息的训练数据进行预测。声音事件检测（SED）[2]是一项定位某些声音类别的开始和偏移的任务。通过结合FSL和SED[3]的思想，一个系统可以只用几个例子来检测一个新的声音类型。少量的SED对于音频数据的标注很有用，特别是当用户需要检测一种新的声音类型时。之前的研究大多使用原型网络[4]作为主要架构[5, 6, 7, 8]。Yang等人[5]提出了一个相互学习的框架，该框架采用过渡推理来迭代改进特征提取器和分类器，其中过渡推理意味着模型在训练过程中可以接触到没有标签的测试集。嵌入空间的平滑流形可以帮助扩展决策边界并减少数据表示中的噪声[9]。Tang等人[6]提出在小样本学习的SED中使用嵌入传播[9]，通过基于相似性图的模型输出特征之间的内插来学习一个更平滑的流形。在[7，8]中描述的方法中，使用了诸如spec-augment和mixup等数据增强。还有一种基于频谱图-交叉相关的方法，称为模板匹配[10]，它根据例子声音事件和未标记数据之间的归一化交叉相关进行检测。</p>
<p>度量学习[11]指的是为一项任务学习距离函数和特征空间。以前基于度量学习的研究[5, 6]通常用标记的正面事件来优化模型，通过对具有相同和不同类别的事件的潜在原型分别进行分组和分离。不包含目标事件的音频块，我们称之为负面事件，其数量较大，但受到的关注较少。例如，在DCASE 2022任务5开发集[10]中，负面事件的持续时间为19.18小时，占训练数据的91.3%，总时间为21小时。</p>
<p>在本文中，我们提出了一个分段级的度量学习方法，在小样本学习的生物声学检测任务上取得了最先进的结果。如图1所示，我们的系统在段级上运行。每个声音事件可以包含多个片段。我们训练一个特征提取网络，将片段映射到潜伏嵌入中，这些嵌入被平均到原型中以代表不同的声音类别。为了学习一个稳健的潜伏空间，我们使用了一个过渡性的学习方案，并提议用负面事件建立对比性损失。我们还通过使用特征选择、数据增强和后处理来改进我们的方法。我们进行了消融研究以衡量每个组成部分的有效性。我们提出的方法在DCASE任务5验证集上取得了62.73的F值。本文将组织如下。第2节提供了我们系统的概述。第3节介绍了我们的方法。第4节讨论了实验设置。第5节报告评估结果和消融研究。第6节总结了这项工作并提供了一个结论。</p>

        <h1 id="系统概述"   >
          <a href="#系统概述" class="heading-link"><i class="fas fa-link"></i></a><a href="#系统概述" class="headerlink" title="系统概述"></a>系统概述</h1>
      <p>我们使用一个原型网络[4]建立我们的系统，该网络被广泛用于基于度量的小样本学习。训练数据T &#x3D; (Si, Yi)|Ntrain i&#x3D;1包含音频特征集Si &#x3D; {si|yi &#x3D; 1} t { ∼ si|yi &#x3D; 0}及其相应的标签集Yi &#x3D; {yi|yi∈ {0, 1}}，其中{si}和{ ∼ si}分别是i类的正片和负片的集合，Ntrain是训练片段的总数目。评估数据集E &#x3D; (S′ i, Y ′ i )|Neval i&#x3D;1还包含一个音频特征集S′ i &#x3D; {s′ i}和一个标签集Y′ i &#x3D; {y′ i}，其中Neval是评估集中的类的数量，|S′ i| &#x3D; Li和|Y ′ i| &#x3D; K。这里我们有Li≥K，因为评价集只有前K个事件的部分标签。我们系统的目标是将不同的音频特征正确地映射到高维空间的潜伏嵌入中，其中类似的音频特征比较接近。</p>
<p>我们使用轮次训练[12]，以N-way-M-shot的方式优化我们的系统。如图2(a)所示，N-way-Mshot意味着每个训练批次将选择N个类的数据。对于每个类i，系统将随机选择M个片段{ss ij }j&#x3D;1…M作为支持片段，另外M个片段{sq ij }j&#x3D;1…M作为查询片段。所有不同类别的片段都有相同的长度。然后，一个特征提取网络（第3.1节）将这些片段映射成固定长度的嵌入，然后将其平均化为查询原型xq i和支持原型xs i。该系统通过最小化查询和支持相同类别的原型之间的距离进行优化。为了建立一个稳健的潜在空间并更好地泛化到新的类别，我们建议在第3.2节和3.3节中使用度量学习中的负面事件和过渡性推理方案。</p>
<p>在评估过程中，音频文件将使用一个具有自适应段长的滑动窗口进行分割（第3.4节）。标记部分的片段将被用来建立正面和负面的原型，这些原型被视为音频文件中正面和负面事件的潜在代表。未标记部分的片段是查询集，可以通过计算和比较与正、负原型的距离来进行分类（第3.5节）。而如果一个查询属于正向原型的概率大于阈值h，它将被归为正向。连续的正面预测将被合并为一个单一的事件。</p>

        <h1 id="方法论"   >
          <a href="#方法论" class="heading-link"><i class="fas fa-link"></i></a><a href="#方法论" class="headerlink" title="方法论"></a>方法论</h1>
      <p>特征提取网络 我们的特征提取网络fθ是一个基于卷积神经网络（CNN）的架构，它将音频特征s映射到潜伏嵌入x中。与[13]提出的架构类似，网络fθ由三个卷积块组成，隐藏通道大小为64、128和64。每个卷积块由三个二维CNN层组成，具有批量归一化和漏整流线性单元激活[14]。作为基于CNN的网络中常见的技巧[13, 15]，我们在每个块之后应用2×2的最大池，用于下采样和扩大接收场。每个卷积块的输入和输出都有一个由下采样CNN层处理的剩余连接。为了在不同的输入长度下保持相同的输出维度，我们在网络的末端应用自适应平均池化。自适应池化后的最终输出特征图是一个C×T×F大小的块，这就是s的最终潜伏嵌入。</p>

        <h1 id="“Segment-level-metric-learning”-Liu-等-2022-p-2-pdf"   >
          <a href="#“Segment-level-metric-learning”-Liu-等-2022-p-2-pdf" class="heading-link"><i class="fas fa-link"></i></a><a href="#“Segment-level-metric-learning”-Liu-等-2022-p-2-pdf" class="headerlink" title="“Segment-level metric learning” (Liu 等, 2022, p. 2) (pdf)"></a>“Segment-level metric learning” (<span class="exturl"><a class="exturl__link"   href="zotero://select/library/items/BYLIN3NY" >Liu 等, 2022, p. 2</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>) (<span class="exturl"><a class="exturl__link"   href="zotero://open-pdf/library/items/GMG38YGH?page=2" >pdf</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>)</h1>
      <p>我们建议在模型优化过程中利用负面事件中的负面片段来学习更稳健的表示，如图2（b）所示。与[3]类似，我们首先将音频特征划分为长度相等的片段，用于度量学习。然后fθ将所有的片段映射成潜伏嵌入。在优化过程中，我们将计算查询原型xq i的类概率分布，这涉及到与所有正面和负面支持原型的距离计算。在这种情况下，模型可以从负面事件中学习到更多的关于建立潜在空间的对比性信息。具体来说，我们首先根据公式1计算出一个距离矩阵D&#x3D;[d(1), d(2), …, d(N)]T。</p>
<p>其中d(i)∈R2N代表xq i与2N个支持原型之间的距离，～ xs j表示j类的负面事件的支持原型。然后，我们通过最大化xq i接近第i类的正支持原型xs i的概率来优化我们的模型，给出的结果是</p>
<p>其中0≤i，j≤N，i，j∈N，l是目标函数。注意，学习过程不涉及负面事件～xq i的查询原型，因为～xq i和～xs i不能保证有相同的声音类型。</p>
<p>数据平衡在这个任务中很重要，因为不同的声音类别有不同的总时长[10]。为了平衡不同的类别，我们在轮次训练中对每个类别进行等概率的采样。这样一来，模型对每个类别的关注概率相等，就不容易出现过拟合的情况。</p>

        <h1 id="“Transductive-inference”-Liu-等-2022-p-2-pdf"   >
          <a href="#“Transductive-inference”-Liu-等-2022-p-2-pdf" class="heading-link"><i class="fas fa-link"></i></a><a href="#“Transductive-inference”-Liu-等-2022-p-2-pdf" class="headerlink" title="“Transductive inference” (Liu 等, 2022, p. 2) (pdf)"></a>“Transductive inference” (<span class="exturl"><a class="exturl__link"   href="zotero://select/library/items/BYLIN3NY" >Liu 等, 2022, p. 2</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>) (<span class="exturl"><a class="exturl__link"   href="zotero://open-pdf/library/items/GMG38YGH?page=2" >pdf</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>)</h1>
      <p>在训练过程中，我们采用了过渡性推理[17]的方法，这意味着我们的模型将在完全标记的训练集和部分标记的评估数据上进行优化。评估数据中的每个文件都有第一个K标记的特定类型的声音的事件。我们把这K个事件作为正面事件，而把标记部分的其余K个音频块作为负面事件。在评价集中，虽然每个文件的声音类型不可用，但具有相同声音类型的文件应该在同一个子文件夹中，我们把评价集中的每个子文件夹视为不同的声音类型。尽管每个子文件夹中的文件不一定都包含相同的目标声音，但我们的实验表明，通过这种方式进行归纳推理，仍然可以帮助模型获得对评价集更好的适应（第3节）。</p>

        <h1 id="“Adaptive-segment-length”-Liu-等-2022-p-3-pdf"   >
          <a href="#“Adaptive-segment-length”-Liu-等-2022-p-3-pdf" class="heading-link"><i class="fas fa-link"></i></a><a href="#“Adaptive-segment-length”-Liu-等-2022-p-3-pdf" class="headerlink" title="“Adaptive segment length” (Liu 等, 2022, p. 3) (pdf)"></a>“Adaptive segment length” (<span class="exturl"><a class="exturl__link"   href="zotero://select/library/items/BYLIN3NY" >Liu 等, 2022, p. 3</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>) (<span class="exturl"><a class="exturl__link"   href="zotero://open-pdf/library/items/GMG38YGH?page=3" >pdf</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>)</h1>
      <p>在训练期间，为了方便批量处理，我们在所有类别中使用相同的段长。但是在评估过程中，使用相同的片段长度并不理想。例如，使用太长或太短的片段长度将分别倾向于有一个高的假阴性率或假阳性率。在评估集中，不同的动物或鸟类的发声长度有很大的不同，从30毫秒到5秒不等。因此，我们选择在评估过程中使用自适应的片段长度。</p>
<p>如表1所示，我们根据标记事件的最大长度tmax &#x3D; max(t1, …, tK )，为每个音频文件设置不同的片段长度，其中t1, …, tK表示K个标记的正面事件的持续时间。我们将跳跃长度设定为窗口长度的三分之一。注意这里的参数是根据经验选择的。</p>

        <h1 id="“Positive-and-negative-prototypes”-Liu-等-2022-p-3-pdf"   >
          <a href="#“Positive-and-negative-prototypes”-Liu-等-2022-p-3-pdf" class="heading-link"><i class="fas fa-link"></i></a><a href="#“Positive-and-negative-prototypes”-Liu-等-2022-p-3-pdf" class="headerlink" title="“Positive and negative prototypes” (Liu 等, 2022, p. 3) (pdf)"></a>“Positive and negative prototypes” (<span class="exturl"><a class="exturl__link"   href="zotero://select/library/items/BYLIN3NY" >Liu 等, 2022, p. 3</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>) (<span class="exturl"><a class="exturl__link"   href="zotero://open-pdf/library/items/GMG38YGH?page=3" >pdf</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>)</h1>
      <p>在评估过程中，我们假设前K个标记的正面事件不包含太多种类，因此我们通过平均标记的正面片段的嵌入来计算正面原型。相比之下，建立负面原型就比较麻烦了，因为负面片段可能包含许多不同种类的声音。因此，简单地对所有的负面嵌入进行平均，会导致负面原型的次优表现。为了解决这些挑战，我们选择运行我们的评估六次，每次选择30个随机选择的负片断，在标记的负片断中，我们平均六次运行的预测概率作为最终预测。每次运行中的负片原型可以有机会代表不同的声音。这个过程类似于随机子空间方法[18]，用不同的训练数据子集训练的几个估计器的集合可以胜过在全部训练数据上优化的单一估计器。</p>

        <h1 id="实验"   >
          <a href="#实验" class="heading-link"><i class="fas fa-link"></i></a><a href="#实验" class="headerlink" title="实验"></a>实验</h1>
      <p>DCASE2022-T5 DCASE 2022任务5数据集2包含一个训练集、一个验证集和一个官方评估集。训练集和验证集都是全标签的。官方评估集有前五个正面事件的标签。在撰写本文时，官方评价集的完整标签还没有公布，因此，在本文中，我们按照[19, 20]将验证集视为评价集。训练期间的验证并不是为了挑选最佳模型。这是因为我们以不同于评估的方式进行验证。与训练过程类似，我们在固定长度的片段水平上计算验证的准确性，没有自适应的片段长度。因此，验证中的最佳模型不一定在评估中表现最好。尽管如此，我们在实验中使用了相同的验证过程，因此在不同的环境下进行的比较是公平的。在[21，22]中也有类似的想法，它们利用评估集进行验证。</p>
<p>AudioSet-Aminal-SL AudioSet[23]是一个用于音频研究的大规模数据集[13, 24]。考虑到DCASE2022-T5的训练集只包含47个不同的声音类别，我们选择使用AudioSet数据集3的强标签部分，以增加训练数据的种类。为了缓解领域不匹配的问题，我们只使用与动物发声有关的声音标签，并且不与其他非动物声音重叠。经过数据清理，我们从AudioSet中得到了1796个具有37个类别的音频。然而，即使声音在AudioSet中具有相同的标签，它们的声音仍然可能非常不同。为了缓解这个问题，我们把AudioSet中的每个音频文件都当作自己的类，所以我们在这个数据集中有1796个类，它被命名为AudioSet-Aminal-SL，其中SL表示强标签。为了平衡AudioSet-Aminal-SL和DCASE2022-T5中的1796个类和47个类，我们在轮次训练中从每个数据集中选择一半的类。</p>
<p>我们使用DCASE任务5的组织者提供的官方评价指标F-measure分数作为我们的主要评价指标。我们还用多声部声音检测得分（PSDS）[25]报告系统性能，这是一个基于交集的声音事件检测的稳健评价指标。在PSDS中，我们将检测容忍度标准（DTC）和地面真实相交标准（GTC）设定为0.5，最大有效误判率为100.0。其他参数如交叉触发容限准则（CTTC）没有被使用，因为我们的任务不是多声道检测。</p>
<p>按照[5]，所有的音频数据都被重新取样为22.5kHz的采样率。我们系统的输入特征是PCEN[26]和∆MFCC[27]特征的堆叠。在短时傅里叶变换中，我们设定窗长为1024，跳数为256。我们将melf frequency维度设置为128。在训练过程中，我们模型的输入长度为0.2秒。如果声音事件小于0.2秒，将应用零填充。第3.1节中提到的嵌入的大小为2048，其中C&#x3D;64，T&#x3D;4，F&#x3D;8。所有的实验都使用0.001的初始学习率，每10个历时有0.65的指数衰减。我们在每个历时后进行验证。我们以3-5-shot的方式进行验证，因为在验证集中只有三个类（HB、ME、PB）。如果连续10个历时的验证精度没有提高，我们将停止模型训练。而具有最佳验证准确率的模型被用于评估。为了充分利用训练数据，我们实现了一个动态数据加载器，该加载器在飞行中生成具有随机起始时间的训练数据。我们假设某种动物的一次发声时间不会有很大的变化。因此，我们根据阳性事件的最大长度 tmax &#x3D; max(t1, …, tK )来设计一个声音类别的后期处理策略。如果一个阳性检测的长度小于α ∗ tmax或大于β ∗ tmax，我们将删除它。在评估过程中，我们使用β&#x3D;2.0，α&#x3D;[0.1, 0.2, …, 0.9]，以及阈值h&#x3D;[0.0, 0.05, …, 0.95]。我们使用β、α、h的不同组合来计算数据点[25]，绘制PSD-ROC曲线，并计算PSDS。我们在所有β, α, h的组合中选择最佳的F-measure作为最终的F-measure。</p>

        <h1 id="结果"   >
          <a href="#结果" class="heading-link"><i class="fas fa-link"></i></a><a href="#结果" class="headerlink" title="结果"></a>结果</h1>
      <p>我们的系统在评估集上的表现报告在表2中。模板匹配和我们重新实现的原型网络基线[10]的F-measure得分分别为4.28和34.02。我们的系统在很大程度上超过了基线，F-measure分数为62.73，PSDS为57.52。</p>
<p>如图3所示，使用转导推理可以显著提高验证的准确性。而从类的ROC来看，HB类，主要是蚊子的声音，是最容易检测的一类。PB类是最难的一类，也许是因为它主要由稀疏的鸟叫声和强背景噪声组成。ME类在评估集中取得了平均性能。</p>
<p>我们对输入特征的影响进行了研究。如图4(a)所示，F-measure和PSDS的性能并不总是一致的，考虑到F-measure在先前的研究中被广泛使用[10]，我们使用F-measure来指导我们的选择。通过比较Fmeasure得分，PCEN+∆MFCC在评估集上似乎是一个好的特征组合。我们还在图4（b）中比较了不同的嵌入维度。我们通过改变自适应平均池中F的维度来改变这个维度。我们注意到512的维度比256的维度有很大的改善，而2048的维度在所有设置中表现最好。</p>
<p>我们对我们提出的每个组件进行消融。如表3所示，如果我们删除负面的片段，性能就会大大下降。这一趋势与过渡性推理和后处理是一样的。我们还研究了训练数据的影响。在表4中，我们可以看到，仅使用DCASE2022-T5就能获得最好的F-measure得分。使用AudioSet-SL会导致46.83的F-measure和51.00的PSDS。通过结合两个数据集，我们得到了58.48的F-measure和58.77的最佳PSDS。我们假设，使用AudioSet的F-measure的下降是由训练数据的领域不匹配造成的。然而，结合两个数据集产生了最好的PSDS，这意味着使用AudioSet数据可以导致所有阈值和后处理设置的普遍改善，而不是得到一个具有高F-measure的单一最佳系统。这表明PSDS可能是一个合适的指标，供社区在这项任务中参考。</p>

        <h1 id="结论"   >
          <a href="#结论" class="heading-link"><i class="fas fa-link"></i></a><a href="#结论" class="headerlink" title="结论"></a>结论</h1>
      <p>本文提出了一个新的框架，用于少见的声音事件检测。我们提出的带负数段的度量学习和归纳推理方案可以显著提高模型性能。在输入特征上，我们的实验表明，在我们的设置中，带有∆MFCC的PCEN产生了最好的性能。我们的结果还表明，通过在评估过程中考虑多个阈值和后处理设置，PSDS可能是评估模型整体性能的一个有用指标</p>
</div></div></article><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/2023/01/01/SE/">Squeeze-and-Excitation Networks-</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">发表于</span><span class="post-meta-item__value">2023-01-01</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">更新于</span><span class="post-meta-item__value">2023-06-18</span></span></div></header><div class="post-body"><div class="post-excerpt">
        <h1 id="摘要"   >
          <a href="#摘要" class="heading-link"><i class="fas fa-link"></i></a><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1>
      <p>  卷积操作：<br>  卷积操作是卷积神经网络(CNNs)的核心构造块，它通过融合每一层局部接受域（感受野）内的空间和信道信息使网络构建信息特征。大量先前的研究已经调查了这种关系的空间成分，试图通过在其特征层次中提高空间编码的质量来提升CNN的表征能力。<br>  本文SE模块：<br>  将重点放在通道关系上提出一个新的架构单元——“Squeeze-and-Excitation”(SE)块。通过显式地建模通道之间的相互依赖，自适应地重新校准信道特征响应。<br>  实验结果：<br>  （1）SE模块可以堆叠在一起，形成SENet架构，在不同的数据集上非常有效地泛化。<br>  （2）SE模块以略微增加的计算成本为现有最先进的CNN带来了显著的性能改进。SENet为2017年ILSVRC分类第一名，并将前5名误差降低到2.251%，比2016年的获奖作品相对提高了25%。<br>  模型和代码：<br>  <span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="https://github.com/hujie-frank/SENet" >https://github.com/hujie-frank/SENet</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></p>

        <h1 id="介绍"   >
          <a href="#介绍" class="heading-link"><i class="fas fa-link"></i></a><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1>
      <p>  ### 卷积神经网络：<br>  已被证明是处理广泛的视觉任务的有用模型。<br>  在网络的每个卷积层，一系列的卷积核表示沿输入通道的邻域空间连通性模式——在局部接受域（感受野）内融合空间和通道信息。通过交错一系列带有非线性激活函数和下采样操作的卷积层，CNN能够产生捕获层次模式的图像表示，并获得全局的理论接受域（感受野）。<br>  ### 计算机视觉的研究中心主题：<br>  寻找更强大的特征表示，这种特征表示只捕捉给定任务中最显著的图像属性，从而提高性能。<br>  CNN作为一种广泛应用于视觉任务的模型，新神经网络架构设计的发展代表计算机视觉研究的一个关键前沿。<br>  ### 最近研究：<br>  最近研究表明，通过将学习机制整合到有助于捕捉特征间空间相关性的网络中，CNN产生的表征可以得到加强。<br>  例：Inception架构将多尺度处理合并到网络模块以提升性能。<br>  进一步工作，寻求更好的模型空间依赖，并将空间注意力融入网络结构。<br> ## 本文：<br>  （1）研究了网络设计的一个不同方面——通道之间的关系。<br>  （2）设计一种新的架构单元——“Squeeze-and-Excitation” (SE)块，其目标是通过显式建模卷积特征通道之间的相互依赖来提高网络产生的表征的质量。 ；<br>  （3）为此本文提出了一种机制，允许网络进行特征重新校准，通过该机制网络可以学习使用全局信息，选择性地强调信息特征和抑制无用的特征。<br>  SE构建块：<br>![[Pasted image 20230301101625.png]]</p>
<p>  对于任意给定变换Ftr(例，卷积)，将输入映射到特征图U（U∈RH×W×C），我们构造一个相应的SE模块来进行特征重新校准：<br>  （1）特征U首先通过“squeeze”操作，通过在空间维度(H ×W)聚合特征图生成通道描述符，该描述符的功能是产生一个通道特征相应的全局分布的嵌入，允许所有层使用来自网络的全局接受域（感受野）的信息。<br>  （2）聚合之后是“ excitation”操作，它采取一个简单的“self-gating”机制的形式，以嵌入作为输入，并产生每个通道调制权值的集合，这些权值被应用到特征图U上，以生成SE模块的输出，该输出可以直接输入到网络的后续层。<br> ## SE模块特点：<br>  （1）简单地堆叠一组SE块就可以构建一个SE网络(SENet)。<br>  （2）SE块可用作网络架构中一定深度的原始块的替代品(6.4节)。<br>  （3）SE构建块的模板是通用的，但SE模块在整个网络的不同深度所扮演的角色不同，在较早的层中，它以与类无关的方式提供信息特性，增强共享的低级表征。在后续层中，SE块变得越来越专门化，并以高度类特定的方式响应不同的输入(7.2节)。因此，由SE模块执行的特征重新校准的好处可以通过网络累积。<br>  新的CNN架构的设计和开发是一项困难的工程任务，通常需要选择许多新的超参数和层配置。<br>  （4）SE模块的结构很简单：可以直接在现有的最先进的架构中使用，通过将组件替换为SE模块组件有效地提高性能。<br>  （5）SE块在计算上是轻量级的：只稍微增加模型的复杂性和计算负担。<br> ## 实验：<br>  开发设计几个SENet，并在ImageNet数据集、ImageNet之外的数据集上的评估结果，表明本文方法的好处并不局限于特定的数据集或任务。<br>  利用SENets，在ILSVRC 2017分类竞赛中获得了第一名。最佳模型集成在测试集上达到了2.251%的top-5误差，与前年的优胜者相比，大约有25%的相对改进(top-5 error为2.991%)。</p>

        <h1 id="相关工作"   >
          <a href="#相关工作" class="heading-link"><i class="fas fa-link"></i></a><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h1>
      <p> ## 更深架构：<br>  （1）VGGNet和Inception模型：表明，增加网络深度可以显著提高其学习的表征质量。通过调节输入到每一层的分布，批处理归一化(BN)增加了深度网络学习过程的稳定性、产生更平滑的优化表面。<br>  （2）ResNets：在上述工作的基础上证明，通过使用identity-based的跳跃连接 ，可以学习相当深和强大的网络。<br>  （3）Highway networks：引入了一种‘gating’机制，以调节shortcut 连接的信息流动。<br>  （4）上述工作之后，一些网络对深度网络的学习和表征特性进行了改进。<br> ## 网络中计算元素的函数形式：<br>  另一个密切相关的研究关注于改进网络中计算元素的函数形式：<br>  （1）分组卷积：已被证明是一种流行的增加学习转换基数的方法。<br>  （2）多分支卷积：可以实现更灵活的算子组合，可以看作是分组操作符的自然扩展。<br>  在之前的工作中，跨通道相关性通常映射为特征的新组合，要么独立于空间结构，要么通过使用具有1×1卷积的标准卷积。这方面的研究主要集中在降低模型和计算复杂度上，反映了一个假设，即通道关系可以被表述为具有局部接受域（感受野）的实例不可知函数的组合。相比之下我们认为，为单元提供一种机制，使用全局信息对通道之间的动态、非线性依赖关系进行显式建模，可以简化学习过程，并显著增强网络的表示能力。<br> ## 架构搜索算法：<br>  除了上述工作，还有一个旨在放弃手工架构设计，寻求自动学习网络架构的丰富的研究历史。这一领域的大部分早期工作是在”neuro-evolution(神经进化)”群落中进行的，使用进化方法建立跨网络拓扑搜索的方法。虽然这些方法通常需要很大的计算代价，但进化搜索已经取得了显著的成功，包括为序列模型找到好的记忆单元、为大规模图像分类学习复杂的体系结构。为减少这些方法的计算负担，基于Lamarckian继承和可微架构搜索提出了有效的替代方法。<br>  通过将架构搜索制定为超参数优化、随机搜索和其他更复杂的基于模型的优化技术也可以用来解决这个问题。拓扑选择（一个通过所有可能设计的路径）和直接架构预测已被提议为其他可行的架构搜索工具。 通过强化学习的技术已经获得了特别强劲的结果。SE模块可以作为这些搜索算法的原子构建块，并且在并发工作中被证明是非常有效的。<br> ## 注意力和“gating ”（闸门）机制：<br>  注意力可以被解释为一种将可用的计算资源分配偏向于信号中信息含量最高的部分的方法。注意机制已经在许多任务中展示了它们的效用，包括序列学习 、图像定位和理解 、图像字幕和唇读，在这些应用程序中，它可以被合并为在一个或多个层之后的操作符，代表更高级的抽象，以适应模式之间的差异。一些工作对空间和通道注意力的结合使用提供了有趣的研究。<br>  Wang等人在深度残差网络的中间阶段插入沙漏模块，引入了一种强大的trunk-and-mask注意机制；本文SE模块包含一个轻量级的门控机制，该机制通过以计算效率高的方式建模通道关系来增强网络的表示能力。</p>

        <h1 id="SQUEEZE-AND-EXCITATION模块"   >
          <a href="#SQUEEZE-AND-EXCITATION模块" class="heading-link"><i class="fas fa-link"></i></a><a href="#SQUEEZE-AND-EXCITATION模块" class="headerlink" title="SQUEEZE-AND-EXCITATION模块"></a>SQUEEZE-AND-EXCITATION模块</h1>
      <p>  “Squeeze-and-Excitation”模块是一个计算单元，它可以建立在变换Ftr上，将输入X∈RH’×W’×C’映射为特征图U∈RH×W×C。<br>  Ftr为卷积算子； V &#x3D; [v1,v2，…vC]表示学习到的卷积核集合，其中vc表示第c个卷积核的参数； 输出为U &#x3D; [u1,u2，…uC]<br>  ![[Pasted image 20230301101924.png]]</p>
<p>其中∗表示卷积![[Pasted image 20230301101941.png]]，<br>![[Pasted image 20230301101956.png]]，并且![[Pasted image 20230301102012.png]]，![[Pasted image 20230301102032.png]]<br>表示2D空间卷积核，代表vc的单个通道作用于x的对应通道。为了简化表示，省略偏置项。由于输出是通过所有通道求和产生的，通道依赖关系隐式嵌入到vc中，但与卷积核捕获的局部空间相关性纠缠在一起。<br>  通过卷积建模的通道关系是固有的、隐式的和局部的(除了最顶层的)，本文期望通过显式建模通道相互依赖来增强卷积特征的学习，使网络能够提高其 对可被后续的转换 利用的信息特征的敏感性。因此我们希望为它提供获取全局信息的途径，在被送入下一个变换之前，通过“squeeze”和“excitation”两步重新校准卷积核的响应。</p>

        <h1 id="Squeeze：全局信息嵌入"   >
          <a href="#Squeeze：全局信息嵌入" class="heading-link"><i class="fas fa-link"></i></a><a href="#Squeeze：全局信息嵌入" class="headerlink" title="Squeeze：全局信息嵌入"></a>Squeeze：全局信息嵌入</h1>
      <p> ## 通道依赖问题：<br>  为了解决利用通道依赖的问题，首先考虑输出特征中每个通道的信号。每一个学习到的卷积核，有一个局部接受域（感受野），因此转换输出U的每个单元无法利用该区域（感受野）以外的上下文信息。<br> ## 方法：<br>  为了缓解上述问题，建议将全局空间信息压缩（ squeeze）到一个通道描述符——使用全局平均池化来生成通道（channel-wise）统计量。在形式上，统计量z∈RC是由U通过其空间维数H ×W收缩产生的，z的第c项元素由以下方式计算:<br>![[Pasted image 20230301102115.png]]</p>

        <h2 id="讨论："   >
          <a href="#讨论：" class="heading-link"><i class="fas fa-link"></i></a><a href="#讨论：" class="headerlink" title="讨论："></a>讨论：</h2>
      <p>  转换U的输出可以被解释为局部描述符的集合，这些描述符的统计量表示整个图像。利用这些信息在以前的特征工程工作中很普遍，我们使用最简单的聚合技术——全局平均池化（注意：也可以使用更复杂的策略）</p>

        <h1 id="Excitation：自适应调整"   >
          <a href="#Excitation：自适应调整" class="heading-link"><i class="fas fa-link"></i></a><a href="#Excitation：自适应调整" class="headerlink" title="Excitation：自适应调整"></a>Excitation：自适应调整</h1>
      <p> ## 目的：<br>  为了利用在”squeeze”操作中聚合的信息，接着进行第二个操作(Excitation操作)，来完全捕获通道(channel-wise)依赖关系。<br> ## 方法：<br>  为实现上述目标，函数必须符合两个标准：<br>  1）灵活：特别是它必须能够学习通道之间的非线性交互<br>  2）必须学习一种非互斥关系：因为我们希望确保允许强调多个通道(而不是强制一个one-hot激活)。<br>  为了满足这些标准，我们选择使用一个简单的门控（gating）机制和sigmoid激活函数：![[Pasted image 20230301102155.png]]</p>
<p>其中δ为ReLU函数，W1∈RC&#x2F;r×C、 W2∈RC×C&#x2F;r。为了限制模型的复杂性、有助于推广，在非线性周围形成包含两个全连接层(FC)的瓶颈（降维比为r）来参数化门控（gating）机制，一个ReLU、一个维度增加的层用于返回到变换输出U的通道维度。块的最终输出通过激活s重新缩放U得到：<br>![[Pasted image 20230301102213.png]]<br>其中![[Pasted image 20230301102225.png]]，![[Pasted image 20230301102239.png]]<br>，是指标量sc和特征图uc∈RH×W的通道（channel-wise）乘法</p>

        <h2 id="讨论：-1"   >
          <a href="#讨论：-1" class="heading-link"><i class="fas fa-link"></i></a><a href="#讨论：-1" class="headerlink" title="讨论："></a>讨论：</h2>
      <p>  Excitation操作将特定于输入的描述符z映射到一组通道权重。SE块从本质上引入了以输入为条件的动力学，可以将其视为通道上的自注意力函数，这些通道的关系不限于卷积滤波器响应的局部接收场。（感受野）<br>#注意事项：最后一个字符不能时反斜杠 </p>

        <h1 id="实例化"   >
          <a href="#实例化" class="heading-link"><i class="fas fa-link"></i></a><a href="#实例化" class="headerlink" title="实例化"></a>实例化</h1>
      <p>  通过在每次卷积后的非线性后插入，SE块可以集成到VGGNe等标准架构中。此外SE块的灵活性意味着它可以直接应用于标准卷积之外的转换。为了说明这一点，我们通过将SE块合并到几个更复杂架构的示例中来开发SENets，下面将对此进行描述：<br>  （1） Inception 网络的SE块的构建： 简单地将转换Ftr作为一个完整的Inception模块(见图2)，通过对架构中的每个这样的模块进行更改，获得了一个SE-Inception网络。<br>![[Pasted image 20230301102323.png]]<br>（2）SE模块可以直接与Res网络一起使用：(图3 SE- resnet模块)。SE块变换Ftr被认为是残差模块的非恒等分支。挤压和激励都是在同分支相加之前起作用的。<br>![[Pasted image 20230301102332.png]]<br>  （3）将SE块与ResNeXt、Inception-ResNet、MobileNet和ShuffleNet整合的进一步变体可以通过类似的方案构建。<br>  ![[Pasted image 20230301102358.png]]<br>  <br>  （表1 SE-ResNet-50和SE-ResNeXt-50的详细描述。）<br>  SE块灵活性的一个结果是，有几种可行的方法将其集成到各种体系结构。</p>

        <h1 id="模型和计算复杂度"   >
          <a href="#模型和计算复杂度" class="heading-link"><i class="fas fa-link"></i></a><a href="#模型和计算复杂度" class="headerlink" title="模型和计算复杂度"></a>模型和计算复杂度</h1>
      <p>  为了使提议的SE块设计具有实际用途，它必须在改进性能和增加模型复杂性之间提供良好的平衡。<br>  ## （1）计算复杂度：<br>  为了说明与模块相关的计算负担，以ResNet-50和SE-ResNet-50之间的比较为例。对于224 × 224像素的输入图像，Renet -50在单次向前传递中需要~ 3.86 GFLOPs。每个SE块在squeeze阶段使用一个全局平均池化操作，在Excitation阶段使用两个小的FC层，随后是一个廉价的通道缩放操作。 总的来说，当将衰减率r设置为16时，SE-ResNet-50需要约3.87 GFLOPs，相对原始ResNet-50增加了0.26%，除了这一点额外的计算负担SE-ResNet-50的精度超过了ResNet-50，接近更深层的ResNet-101网络（7.58GFLOPs），(表2)。<br>![[Pasted image 20230301102417.png]]</p>
<p>  在实际操作中，通过ResNet-50一次来回传递需要190 ms，而SE-ResNet-50只需要209 ms(在带有8个NVIDIA Titan X gpu的服务器上执行)。对每个模型的CPU推断时间进行基准测试，ResNet-50需要164毫秒，而SE-ResNet-50需要167毫秒。由于SE块对模型性能的贡献，它所产生的少量额外计算成本是合理的。<br>  ## （2）参数量：<br>  接下来考虑SE块引入的附加参数，额外的参数仅仅来自门控（gating）机制的两个FC层，因此构成了整个网络容量的一小部分。 具体而言，各FC层权重参数引入的总个数为:<br>![[Pasted image 20230301102452.png]]</p>
<p>r表示减衰减率，S是指阶段的数量(阶段是指一个共同的空间维度的特征图上操作的块的集合)，Cs表示输出通道的尺寸，Ns代表阶段s中重复的块的数量(当在FC层中使用偏置时，引入的参数和计算成本通常可以忽略不计)。<br>  SE-ResNet-50引入了超过250万个额外参数Renet -50所需要的参数约为2500万个，对应的增长约为10%。在实践中额外参数中的大部分来自于网络的最后阶段，在这一阶段excitation操作是在最大数量的通道中执行。然而后续实验发现这种相对昂贵的最后阶段的SE块可以删除，性能代价很小。</p>

        <h1 id="实验"   >
          <a href="#实验" class="heading-link"><i class="fas fa-link"></i></a><a href="#实验" class="headerlink" title="实验"></a>实验</h1>
      <p>  本节进行实验来研究在一系列任务、数据集和模型架构中SE块的有效性。</p>

        <h2 id="5-1-图像分类"   >
          <a href="#5-1-图像分类" class="heading-link"><i class="fas fa-link"></i></a><a href="#5-1-图像分类" class="headerlink" title="5.1 图像分类"></a>5.1 图像分类</h2>
      <p>  ### ImageNet 数据集的实验：<br>  （1）数据集：为了评估SE块的影响，首先在ImageNet 2012数据集上进行实验，该数据集包括来自1000个不同类的128万张训练图像和50K的验证图像。在训练集上训练网络，并在验证集上报告top-1和top-5错误。<br>  （2）训练设置：每个基线网络结构及其SE对等体都用相同的优化方案进行训练；遵循标准做法，使用大小为224 × 224像素的比例和宽高比随机裁剪数据执行数据增强，并执行随机水平翻转；每个输入图像通过平均rgb通道减法进行归一化；所有模型都在分布式学习系统ROCS上进行训练，该系统旨在处理大型网络的高效并行训练；优化器使用具有动量0.9和1024小批量大小的SGD；初始学习率设置为0.6，每30个epoch降低10倍；使用权值初始化策略，从零开始训练模型100个epoch。缩减比r默认设置为16；<br>  （3）评估设置：应用中心裁剪，使每幅图像裁剪224 × 224像素它的短边首先被调整为256(对于Inception-ResNet-v2和SE-Inception-ResNet-v2，每个图像的短边被调整为352)。<br>  （4）网络深度：<br>![[Pasted image 20230301102536.png]]</p>
<p>  比较SE-ResNet和不同深度的ResNet架构，如表2：<br>  1）SE块在不同深度上一致地提高了性能，同时计算复杂度上有非常小的增加：SE-ResNet-50获得6.62%的 single-crop top-5验证误差，比ResNet-50(7.48%)高0.86%，接近深度更大的ResNet-101 (6.52% top-5误差)，而总计算量只有其一半(3.87 GFLOPs vs. 7.58 GFLOPs)；这一模式在更大的深度上重复，其中与SE-ResNet-101(6.07%的top-5误差)不仅匹配，而且比更深的ResNet-152 (6.34% top-5误差)性能高0.27%。<br>  2）SE块本身增加了深度，但它们以一种极其高效的计算方式这样做，并且即使在扩展基本架构的深度达到收益递减的情况下也会产生良好的收益。<br>  3）增益在一系列不同的网络深度上是一致的，这表明SE块所引起的改进可能是通过简单地增加基础架构的深度所获得的改进的补充。<br>  （5）与当代架构的融合：<br>![[Pasted image 20230301102550.png]]</p>
<p>  1）研究将SE模块与另外两种最先进的架构整合的效果：incept - resnet -v2和ResNeXt，这两种架构都将额外的计算构建模块引入到基本网络中，构建了这些网络的SENet等价物SE-Inception-ResNet-v2 和 SE-ResNeXt(配置如表1)，表2实验结果表明： 在两个体系结构中引入SE块带来显著性能改进。其中，SE-ResNeXt-50的top-5误差为5.49%，优于直接对应的ResNeXt-50 (5.90% top-5误差)和更深层次的ResNeXt-101 (5.57% top-5误差)，后者的参数总数和计算开销几乎是前者的两倍。SE对等物(4.79% top-5误差)比重新实施的Inception-ResNet-v2baseline基线(5.21% top-5误差)结果高出0.42%。<br>  2）评估SE块在非残差网络上运行时的影响：通过使用VGG-16 和BN-Inception架构 进行实验 。为了便于VGG-16的从头训练，我们在每次卷积后都添加批处理归一化层。对VGG-16和SE-VGG-16使用相同的训练方案。对比结果如表2： 与Res基线架构报告的结果类似，SE块在非Res架构设置上带来性能改进。<br>  3）SE块对模型优化的影响，图4描述基线架构和它们各自SE对等体运行的示例训练曲线。 SE块在整个优化过程中产生了稳定的改进，这种趋势在一系列被视为基线的网络架构中是相当一致的。<br>  （6）移动设置：<br>![[Pasted image 20230301102605.png]]</p>
<p>  考虑两种典型的移动优化网络架构：MobileNet 和ShuffleNet 。 实验使用256的批量大小和稍微不那么激进的数据增强和正则化 ；使用带有动量(设置为0.9)的SGD在8个gpu上训练模型，初始学习率为0.1，当验证损失趋于稳定时，学习率降低10倍。整个训练过程需要400个epoch。实验结果如表3： SE块以极小的计算成本持续增加精度。<br>  额外数据集的实验：<br>![[Pasted image 20230301102626.png]]</p>
<p>  （1）目的：研究SE块的好处是否适用于ImageNet以外的数据集。<br>  （2）实验架构、数据集：用几种流行的基线架构和技术(ResNet-110 ， ResNet-164 ， WideResNet-16-8， Shake-Shake和Cutou)在CIFAR-10和CIFAR-100数据集 上进行实验，包括一个50k训练和10k测试的集合，32 × 32像素的RGB图像，分别标记为10和100类。<br>  （3）实验设置：将SE块集成到上述网络，每个基线和它的SENet对等物都用标准的数据增强策略进行训练；在训练过程中图像被随机水平翻转，每边用4个像素进行零填充，然后随机抽取32 × 32的crop；应用平均值和标准偏差；训练超参数设置(如小批量大小、初始学习率、权值衰减)与原始论文的建议一致。<br>  表4，每个基线及其SENet对等物在CIFAR-10上的性能，表5报告CIFAR-100上的性能：<br>  SENet优于基线架构，表明SE块的好处并不局限于ImageNet数据集。</p>

        <h2 id="5-2-场景分类"   >
          <a href="#5-2-场景分类" class="heading-link"><i class="fas fa-link"></i></a><a href="#5-2-场景分类" class="headerlink" title="5.2 场景分类"></a>5.2 场景分类</h2>
      <p>  ### Places365-Challenge数据集：<br>  Places365-Challenge数据集上进行了场景分类实验，包含800万张训练图像和36500张验证图像，跨越365个类别。相对于分类，场景理解的任务提供了另一种评估模型的能力，以很好地概括和处理抽象，这是因为它通常要求模型处理更复杂的数据关联，并对更大级别的外观变化具有鲁棒性。<br>  实验设计与结果：<br>![[Pasted image 20230301102652.png]]</p>
<p>  我们选择使用ResNet-152作为一个强基线来评估SE块的有效性。实验中模型从零开始训练。表6与之前工作比较的实验结果：<br>   SE-ResNet-152 (11.01% top-5误差)的验证误差低于ResNet-152 (11.61% top-5误差)，表明SE块也可以改善场景分类，SENet超过了之前最先进的模型 Places-365-CNN（11.48%的 top-5错误）</p>

        <h2 id="5-3-COCO目标检测"   >
          <a href="#5-3-COCO目标检测" class="heading-link"><i class="fas fa-link"></i></a><a href="#5-3-COCO目标检测" class="headerlink" title="5.3 COCO目标检测"></a>5.3 COCO目标检测</h2>
      <p>  评估COCO数据集目标检测任务上SE模块的泛化。<br>  实验设置：<br>  （1）数据集：在之前的工作中使用minival策略，即在80k的训练集和35k的val子集的并集上训练模型，并在其余5k的val子集上评估。<br>  （2）权重（预训练模型）：权重由在ImageNet数据集上训练的模型参数初始化。<br>  （3）检测架构：使用Faster R-CNN检测框架，并遵循原文描述的超参数设置。<br>  实验目标：<br>  评估用SE-ResNet替换目标检测器中的主干架构(ResNet)的效果，以便性能上的任何变化都可以归因于更好的表示。<br>  实验结果：<br>![[Pasted image 20230301102712.png]]</p>
<p>  表7使用ResNet-50、ResNet-101及其SE对等体作为架构的目标检测器的验证集性能。<br>  SE-ResNet-50比ResNet-50的COCO标准AP指标高出2.4%(相对提高6.3%)，比AP@IoU&#x3D;0.5高出3.1%。SE块也受益于更深层次的ResNet-101架构，在AP度量上提高了2.0%(相对提高了5.0%)。<br>  结论：<br>  综上所述，实验证明了SE模块的普遍性。改进可以在广泛的架构、任务和数据集上实现。</p>

        <h2 id="5-4-ILSVRC-2017分类竞赛"   >
          <a href="#5-4-ILSVRC-2017分类竞赛" class="heading-link"><i class="fas fa-link"></i></a><a href="#5-4-ILSVRC-2017分类竞赛" class="headerlink" title="5.4 ILSVRC 2017分类竞赛"></a>5.4 ILSVRC 2017分类竞赛</h2>
      <p>  SENets在ILSVRC2017竞赛获得了第一名，获奖作品由一小群SENets组成，采用了标准的multi-scale 和 multi-crop融合策略，在测试集上获得了2.251%的top-5误差。<br>![[Pasted image 20230301102726.png]]</p>
<p>  表8：<br>  SENet-154整合SE块和修改后的ResNeXt，将此模型与表8中使用标准crop size的ImageNet验证集的先前工作进行了比较(224×224和320×320）发现SENet-154的top-1误差为18.68%，top-5误差为4.47%，在报告结果中是最强的。<br>![[Pasted image 20230301102734.png]]</p>
<p>  表9：<br>  包含目前知道的最强有力的结果。AmoebaNet方法：在训练过程中使用强化学习来开发新的数据增强策略，以提高搜索体系结构的性能；ResNeXt-101 32 × 48d 架构：通过在大约10亿张弱标记图像上预训练他们的模型并在ImageNet上进行微调来实现最佳的总体性能。<br>  更复杂的数据增强（AmoebaNet）和广泛的预训练（ResNeXt-101 32 × 48d）产生的改进可能是对我们提出的网络架构变化的补充。</p>

        <h1 id="6-消融实验"   >
          <a href="#6-消融实验" class="heading-link"><i class="fas fa-link"></i></a><a href="#6-消融实验" class="headerlink" title="6 消融实验"></a>6 消融实验</h1>
      <p>  本节进行消融实验，以更好地了解使用不同构型对SE模块的影响。<br>  实验设置：<br>  （1）数据集与环境：所有消融实验都是在一台机器上(8个gpu)的ImageNet数据集上进行的。<br>  （2）骨干架构：采用ResNet-50，根据经验在ResNet架构中，在激励操作中消除FC层的偏差，有助于通道依赖关系的建模，并在以下使用此配置实验。<br>  （3）数据增强策略：遵循5.1节中描述的方法。<br>  （4）学习率：为了研究每个变体的性能上限，学习率初始化为0.1，并继续训练，直到验证损失达到平稳水平（总计约300个时代)。然后将学习速率降低到原来的10倍，重复这个过程(总共三次)。<br>  （5）损失：在训练过程中使用标签平滑正则化 。</p>

        <h2 id="6-1-衰减率"   >
          <a href="#6-1-衰减率" class="heading-link"><i class="fas fa-link"></i></a><a href="#6-1-衰减率" class="headerlink" title="6.1 衰减率"></a>6.1 衰减率</h2>
      <p>![[Pasted image 20230301102759.png]]</p>
<p>  公式5中引入的衰减率r是一个超参数，它允许我们改变网络中SE块的容量和计算成本。 为了研究性能和计算成本之间的平衡，使用SE-ResNet-50在不同的r值范围内进行实验，如表10，结果表明：<br>  （1）性能在一定范围的衰减率下是稳健的。<br>  （2）增加复杂性并不会单调地提高性能，而较小的比例会显著地增加模型参数大小。设置r &#x3D; 16可以很好地平衡准确性和复杂性。<br>  （3）在实践中，在整个网络中使用相同的衰减率可能不是最优的(由于不同的层执行不同的角色)，因此可以通过调整衰减率来满足给定基础架构的需求，从而实现进一步的改进。</p>

        <h2 id="6-2-Squeeze操作"   >
          <a href="#6-2-Squeeze操作" class="heading-link"><i class="fas fa-link"></i></a><a href="#6-2-Squeeze操作" class="headerlink" title="6.2 Squeeze操作"></a>6.2 Squeeze操作</h2>
      <p>![[Pasted image 20230301102823.png]]</p>
<p>  验证使用全局平均池化而不是全局最大池化作为Squeeze操作符的意义。结果如表11：<br>  （1）max和average pooling都是有效的，但是average pooling的性能稍好，证明了选择average pooling作为Squeeze操作。<br>  （2）SE块的性能对于特定聚合操作符的选择是相当健壮的。</p>

        <h2 id="6-3-Excitation操作"   >
          <a href="#6-3-Excitation操作" class="heading-link"><i class="fas fa-link"></i></a><a href="#6-3-Excitation操作" class="headerlink" title="6.3 Excitation操作"></a>6.3 Excitation操作</h2>
      <p>![[Pasted image 20230301102846.png]]</p>
<p>  评估Excitation机制的非线性选择，考虑了两种进一步的选择：ReLU和tanh，并尝试用这些可替代的非线性代替sigmoid。结果见表12：<br>  用sigmoid替换tanh会略微恶化性能，而使用ReLU会显著恶化。实际上会导致SE-ResNet-50的性能低于ResNet-50基线。这表明为了使SE块有效，仔细地构造Excitation是重要的。</p>

        <h2 id="6-4-不同阶段"   >
          <a href="#6-4-不同阶段" class="heading-link"><i class="fas fa-link"></i></a><a href="#6-4-不同阶段" class="headerlink" title="6.4 不同阶段"></a>6.4 不同阶段</h2>
      <p>![[Pasted image 20230301102903.png]]</p>
<p>  通过将SE块整合到ResNet-50中来探索不同网络阶段SE模块块的影响。具体来说，将SE块添加到中间网络阶段：阶段2、阶段3和阶段4，并在表13中报告结果：<br>  我们观察到，在架构的每个阶段引入SE块都会带来性能上的好处，而且不同阶段的SE块所产生的增益是互补的，可以有效地结合在一起，进一步提高网络性能。</p>

        <h2 id="6-5-集成策略"   >
          <a href="#6-5-集成策略" class="heading-link"><i class="fas fa-link"></i></a><a href="#6-5-集成策略" class="headerlink" title="6.5 集成策略"></a>6.5 集成策略</h2>
      <p>![[Pasted image 20230301102920.png]]<br>![[Pasted image 20230301102930.png]]</p>
<p>  （1）评估将SE块整合到现有架构中时，SE位置对结果的影响：<br>  除提出的SE设计，考虑了三种变体：<br>  1) SE-PRE块：其中SE块被移动到残差单元之前;<br>  2) SE-POST块：SE单元移动到identity分支(ReLU之后)相加后<br>  3)SE- identity块：其中SE单元平行于残差单元放置在identity连接上。<br>  图5说明了这些变体，表14报告了每种变体的性能：SE-PRE、SE- identity和提议的SE块在使用时都表现得相似，使用SE-POST块的情况下会导致性能下降——表明SE单元产生的性能改进对于它们的位置来说是相当健壮的，前提是在分支聚合之前应用这些改进。<br>![[Pasted image 20230301102940.png]]</p>
<p>  （2）评估将SE块放置在残差单元结构内，对结果的影响：<br>   构造了一个变种的设计，将SE块移动到残差单元内，直接放置在3 × 3卷积层之后，由于3 × 3的卷积层拥有较少的通道，相应的SE块引入的参数数量也减少了。 表15中的比较表明，SE 3×3变体在参数比标准SE块少的情况下获得了相当的分类精度。我们猜测通过针对特定架构调整SE块的使用，可以进一步提高效率。</p>

        <h1 id="7-SE模块的作用"   >
          <a href="#7-SE模块的作用" class="heading-link"><i class="fas fa-link"></i></a><a href="#7-SE模块的作用" class="headerlink" title="7 SE模块的作用"></a>7 SE模块的作用</h1>
      <p>  SE块已被证明在多个视觉任务中改善网络性能，了解squeeze 操作的相对重要性以及excitation机制在实践中如何运作。</p>

        <h2 id="7-1-Squeeze的作用"   >
          <a href="#7-1-Squeeze的作用" class="heading-link"><i class="fas fa-link"></i></a><a href="#7-1-Squeeze的作用" class="headerlink" title="7.1 Squeeze的作用"></a>7.1 Squeeze的作用</h2>
      <p>![[Pasted image 20230301102959.png]]</p>
<p>  评估Squeeze操作产生的全局嵌入是否在性能上起重要作用<br>   试验SE块的一个变体，它添加了相同数量的参数，但不执行全局平均池化——具体去掉池化操作，在excitation中将两个FC层替换为对应的通道维数相同的1 × 1卷积，即NoSqueeze，其中excitation输出保持与输入相同的空间维数 。<br>  与SE块相反，这些点向卷积只能作为局部运算符输出的函数重新映射信道。而在实践中，深层网络的后几层通常具有(理论上的)全局接受场，全局嵌入不再是直接通过网络的NoSqueeze变量。<br>  表16两种模型的精度、计算复杂度与标准ResNet-50模型的比较。我们观察到全局信息的使用对模型的性能有显著的影响，强调了 squeeze操作的重要性。此外与NoSqueeze设计相比，SE块允许以一种计算节俭的方式使用全局信息。</p>

        <h2 id="7-2-Excitation的作用"   >
          <a href="#7-2-Excitation的作用" class="heading-link"><i class="fas fa-link"></i></a><a href="#7-2-Excitation的作用" class="headerlink" title="7.2 Excitation的作用"></a>7.2 Excitation的作用</h2>
      <p>  为了更清楚地了解SE块中Excitation的功能，研究SE- resnet -50模型的激活，并检查它们在网络中不同深度的不同类别和不同输入图像方面的分布。特别地想要了解excitation如何在不同类的图像之间，以及在一个类中的图像之间变化。<br>![[Pasted image 20230301103015.png]]</p>
<p>  首先考虑不同类的excitation分布：具体来说从表现出语义和外观多样性的ImageNet数据集中采样了四个类，即goldfish、pug、plane和cliff ；然后从验证集中为每个类别抽取50个样本，并计算每个阶段最后一个SE区块(下采样之前)中50个均匀采样通道的平均激活情况，并将其分布绘制在图6中。为了便于参考还绘制了1000个类中平均激活的分布。<br>  对excitation操作的作用有以下三方面的观察：<br>  （1）首先 不同类之间的分布在网络的早期层非常相似，如SE 2-3。这表明在早期阶段，特征通道的重要性可能会被不同的类别所分享。<br>  （2）第二个观察是，在更大的深度，每个通道的值变得更特定于类，因为不同的类对特征的鉴别值表现出不同的偏好，例如SE4-6和SE 5-1。(观察结果与之前的研究结果一致 即较早的层次特征通常更普遍 ，而较晚的层次特征则表现出更高层次的特异性 )<br>  （3）在网络的最后阶段观察到一个有点不同的现象：SE5-2表现出一种有趣的趋向于饱和状态的趋势，在这种状态下大多数的激活接近于1，当所有激活的值都为1时，SE块将简化为identity操作符。SE 5-3中的网络末端(紧接其后的是在分类器之前的全局池)，类似的模式出现在不同的类上，直到规模上的适度变化(可以由分类器调整)。这表明SE 5-2和SE 5-3 在向网络提供重新校准方面不如以前的区块重要。该结果表明，通过去除最后阶段的SE块，可以显著减少附加参数计数，而性能只会有边际损失。<br>![[Pasted image 20230301103027.png]]</p>
<p>  图7为两个样本类(金鱼和飞机)在同一类内的图像实例激活的均值和标准差，可以观察到一个与类间可视化一致的趋势，表明SE块的动态行为在类和类内实例中都有所变化。特别是在网络的后几层中，当一个类内的表示具有相当大的多样性时，网络学习利用特征重新校准来提高其判别性能 。<br>  总之，SE块产生特定于实例的响应，然而这些响应在体系结构的不同层上支持模型日益增长的特定于类的需求。</p>

        <h1 id="8-结论"   >
          <a href="#8-结论" class="heading-link"><i class="fas fa-link"></i></a><a href="#8-结论" class="headerlink" title="8 结论"></a>8 结论</h1>
      <p>  本文：<br>  提出SE模块，这是一个架构单元，旨在通过使网络能够执行动态通道特征重新校准来提高网络的表征能力。<br>  实验：<br>  （1）大量实验证明了SENet的有效性，它在多个数据集和任务中实现了最先进的性能。<br>  （2）SE模块揭示了以前的架构无法充分建模通道方面的特征依赖关系。<br>  （3）由SE块产生的特征重要度值可以用于其他任务，如用于模型压缩的网络剪枝。</p>
</div></div></article><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/2022/11/20/%E5%BA%A6%E9%87%8F%E5%AD%A6%E4%B9%A0/">度量学习</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">发表于</span><span class="post-meta-item__value">2022-11-20</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">更新于</span><span class="post-meta-item__value">2023-06-18</span></span></div></header><div class="post-body"><div class="post-excerpt"><p>度量学习[12][13]是一种机器学习方法，是指通过学习一个距离或相似度度量来解决分类、回归、聚类等问题。在度量学习中，我们试图学习一个函数，将输入样本映射到一个高维空间中的向量，使得相似的样本在该空间中的距离更近，而不相似的样本在该空间中的距离更远。小样本度量学习[14]是指在样本数量较少的情况下，学习一个有效的距离度量来解决分类问题。这种问题通常出现在数据集缺乏或者某些类别的样本数量非常少的情况下。</p>
<p>传统的度量学习方法在面对小样本问题时往往会出现过拟合的问题，因为它们只考虑了相似性和距离的问题，而没有考虑到样本之间的变化和差异性。因此，近年来出现了一些针对小样本度量学习问题的新方法，如Matching Networks、Prototypical Networks和Relation Networks等。本文运用了Prototypical Networks[15]的小样本度量学习方法，它通过学习一个原型向量来表示每个类别，并使用这些原型向量来计算测试样本与每个类别之间的距离，并在距离最小的类别中进行分类。</p>
<p>生物声学事件检测是一项生物学领域新兴的研究，由于动物的叫声在行为学，物种识别研究、动物保护研究、动物疾病诊断等方面都发挥着重要的作用，因此生物声学事件检测越来越被重视。由于深度学习的广泛发展，在生物声学检测中常用的深度学习方法有卷积神经网络（CNN）、循环神经网络（RNN）和注意力机制（Attention）等，其中CNN在生物声学事件检测中被广泛应用，因为它在处理时间序列数据方面具有优秀的性能。</p>
<p>由于原型网络中将数据集分为训练集，验证集和评估集，由于数据集的量少在本文中验证集和评估集使用同样的数据。在训练中，我们先通过每个类别提供的样本计算一个类别表示，如图每个颜色代表一个类别，当我们计算出每个类别的表示之后，当出现新的数据时我们通过计算新数据与每个类别表示的距离来判断数据属于哪个类别。这里距离计算的方法采用度量学习，具体距离函数为：</p>
<p><img src="file:////Users/azai/Library/Group%20Containers/UBF8T346G9.Office/TemporaryItems/msohtmlclip/clip_image001.png" alt="文本
低可信度描述已自动生成"></p>
<p>在训练过程中我们采取了使用负面数据优化模型\cite{bytedance}的策略，使得模型更加稳健。同时，为了提升模型的精度但又防止出现梯度消失和爆炸问题我们在CNN中使用了残差模块并且在CNN之后单独添加了残差模块，残差模块的基本思想是在网络中引入“跳跃连接”，让信息直接从输入层传递到输出层增加输入和输出之间的映射关系，同时，残差模块可以在增加少量参数的情况下加深网络的深度并解决tackle 梯度消失和梯度爆炸问题，提高模型的表达能力和性能。</p>
<p>由于原型网络是基于CNN建立的，而CNN中的卷积核虽然可以降低空间和通道维度，但是空间和通道不能独立的学习，这样就降低了网络的识别效果。在本文提出的MCS-Net网络模型中，增加了空间和通道独立学习的能里，并把这个两个学习结果相加起来，这样既考虑了空间和通道的独立学习又考虑了两者之间的通道关系，增加了网络的编码能力，使得网络的识别效果增加。下面对Channel和Spatial进行分别介绍：<br>在训练过程中我们采取了使用负面数据优化模型\cite{bytedance}的策略，使得模型更加稳健。同时，为了提升模型的精度但又防止出现梯度消失和爆炸问题我们在CNN中使用了残差模块并且在CNN之后单独添加了残差模块，残差模块的基本思想是在网络中引入“跳跃连接”，让信息直接从输入层传递到输出层增加输入和输出之间的映射关系，同时，残差模块可以在增加少量参数的情况下加深网络的深度并解决tackle 梯度消失和梯度爆炸问题，提高模型的表达能力和性能。</p>
</div></div></article><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/2022/10/18/%E8%AF%84%E4%BC%B0%E6%A0%87%E5%87%86/">评估标准</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">发表于</span><span class="post-meta-item__value">2022-10-18</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">更新于</span><span class="post-meta-item__value">2023-06-18</span></span></div></header><div class="post-body"><div class="post-excerpt">
        <h2 id="TP-，FP-，TN-，FN"   >
          <a href="#TP-，FP-，TN-，FN" class="heading-link"><i class="fas fa-link"></i></a><a href="#TP-，FP-，TN-，FN" class="headerlink" title="TP ，FP ，TN ，FN"></a>TP ，FP ，TN ，FN</h2>
      <hr>
<p>TP：实际正例；预测正例；  —被模型预测为正类的正样本<br>FP：实际反例；预测正例；  —被模型预测为正类的负样本<br>TN：实际反例；预测反例；  —被模型预测为负类的负样本<br>FN；实际正例；预测反例；  —被模型预测为负类的正样本</p>

        <h2 id="Recall-，Precision-，FPR-，-Specificity-，F1-score-，MCC"   >
          <a href="#Recall-，Precision-，FPR-，-Specificity-，F1-score-，MCC" class="heading-link"><i class="fas fa-link"></i></a><a href="#Recall-，Precision-，FPR-，-Specificity-，F1-score-，MCC" class="headerlink" title="Recall ，Precision ，FPR ， Specificity ，F1-score ，MCC"></a>Recall ，Precision ，FPR ， Specificity ，F1-score ，MCC</h2>
      <p>![[Pasted image 20230403104135.png]]<br>![[Pasted image 20230403104206.png]]</p>

        <h2 id="macro-avg-，micro-avg-，weighted-avg"   >
          <a href="#macro-avg-，micro-avg-，weighted-avg" class="heading-link"><i class="fas fa-link"></i></a><a href="#macro-avg-，micro-avg-，weighted-avg" class="headerlink" title="macro avg ，micro avg ，weighted avg"></a>macro avg ，micro avg ，weighted avg</h2>
      <p>这里我们以precision，recall为例进行分析。<br>  我们首先清楚一点是，我们在计算recall或者precision的时候,是根据某一类别进行计算的，什么意思呢？比如：我们做二分类，0代表正例，1代表反例。根据这样的定义我们可以计算出 TP FP TN FN 以及precision 和recall 。反过来，我们以1 代表正例，0代表反例，同样可以计算出刚才那一堆。这里的avg 嗯就是对刚才的那一堆进行avg。首先我们来看 macro avg。<br>  macro avg的意思是宏平均，从字面意思我们应该明白大概了。就是对类1的recall值和类0的recall值进行平均，权重是0.5.这个明白了，weighted avg 也差不多啦，weighted avg就是用样本的比例充当权重来计算的。macro avg公式如下<br>![[Pasted image 20230403104303.png]]</p>

        <h2 id="ROC曲线和AUC"   >
          <a href="#ROC曲线和AUC" class="heading-link"><i class="fas fa-link"></i></a><a href="#ROC曲线和AUC" class="headerlink" title="ROC曲线和AUC"></a>ROC曲线和AUC</h2>
      <p>FPR和TPR<br>FPR（False Positive Rate）和TPR（True Positive Rate）分别对应着ROC曲线的横纵坐标，其定义如下 ：<br>![[Pasted image 20230403104356.png]]<br>对于一个学习器它的预测结果只能产生一对（FPR，TPR），这只能绘制一个点，不足以绘制出一条曲线。实际上对于许多学习器在判定二分类问题时是预测出一个对于真值的范围在[0.0, 1.0]之间的概率值，而判定是否为真值则看该概率值是否大于设定的阈值（Threshold）。例如如果阈值设定为0.5则所有概率值大于0.5的均为正例，其余为反例。因此对于不同的阈值我们可以得到一系列相应的FPR和TPR，从而绘制出ROC曲线。<br>以下列数据举例：<br>![[Pasted image 20230403104421.png]]<br>如果我们将他的score值做阈值，也就是说，只有score大于等于0.9时，我们才把样本归类到正样本，这么一来， 在ROC曲线图中，样本1对应的混淆矩阵（confusion matrix）为:<br>![[Pasted image 20230403104803.png]]<br>![[Pasted image 20230403104824.png]]</p>

        <h3 id="AUC绘制说明以及图片来源：https-blog-csdn-net-xiaohuihui1994-article-details-87987836"   >
          <a href="#AUC绘制说明以及图片来源：https-blog-csdn-net-xiaohuihui1994-article-details-87987836" class="heading-link"><i class="fas fa-link"></i></a><a href="#AUC绘制说明以及图片来源：https-blog-csdn-net-xiaohuihui1994-article-details-87987836" class="headerlink" title="AUC绘制说明以及图片来源：https://blog.csdn.net/xiaohuihui1994/article/details/87987836"></a>AUC绘制说明以及图片来源：<span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="https://blog.csdn.net/xiaohuihui1994/article/details/87987836" >https://blog.csdn.net/xiaohuihui1994/article/details/87987836</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></h3>
      
        <h3 id="关于多分类AUC的原理参看：https-blog-csdn-net-YE1215172385-article-details-79443552"   >
          <a href="#关于多分类AUC的原理参看：https-blog-csdn-net-YE1215172385-article-details-79443552" class="heading-link"><i class="fas fa-link"></i></a><a href="#关于多分类AUC的原理参看：https-blog-csdn-net-YE1215172385-article-details-79443552" class="headerlink" title="关于多分类AUC的原理参看：https://blog.csdn.net/YE1215172385/article/details/79443552"></a>关于多分类AUC的原理参看：<span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="https://blog.csdn.net/YE1215172385/article/details/79443552" >https://blog.csdn.net/YE1215172385/article/details/79443552</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></h3>
      
        <h2 id="同时这里给出一个例子："   >
          <a href="#同时这里给出一个例子：" class="heading-link"><i class="fas fa-link"></i></a><a href="#同时这里给出一个例子：" class="headerlink" title="同时这里给出一个例子："></a>同时这里给出一个例子：</h2>
      <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> label_binarize</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBClassifier</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line">iris_X = iris.data</span><br><span class="line">iris_y = iris.target</span><br><span class="line"></span><br><span class="line">y = pd.Categorical(iris_y).codes  <span class="comment"># 将标签转换0,1,...</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(iris_X, iris_y, test_size=<span class="number">0.3</span>)</span><br><span class="line">y_one_hot = label_binarize(y_test, np.arange(<span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">clf=XGBClassifier(random_state=<span class="number">2020</span>)</span><br><span class="line">clf.fit(X_train,y_train)</span><br><span class="line">y_pro=clf.predict_proba(X_test)</span><br><span class="line">y_pre=clf.predict(X_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;AUC:&quot;</span>,metrics.roc_auc_score(y_one_hot,y_pro,average=<span class="string">&#x27;micro&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="number">2</span>、混淆矩阵</span><br><span class="line">metrics.confusion_matrix(y_test, y_pre)</span><br><span class="line"></span><br><span class="line"><span class="number">4</span>、模型报告</span><br><span class="line"><span class="built_in">print</span>(metrics.classification_report(y_test, y_pre))</span><br></pre></td></tr></table></div></figure>


        <h2 id="5-使用"   >
          <a href="#5-使用" class="heading-link"><i class="fas fa-link"></i></a><a href="#5-使用" class="headerlink" title="5 使用"></a>5 使用</h2>
      <p>下面是sklearn的部分代码：</p>
<p>&#96;&#96;&#96;python<br> predicted &#x3D; cross_val_predict(classifier, X, y, cv&#x3D;cv, n_jobs&#x3D;cpu_num)<br> predict_prob &#x3D; cross_val_predict(classifier, X, y, cv&#x3D;cv, n_jobs&#x3D;cpu_num, method&#x3D;’predict_proba’)<br> AUC &#x3D; metrics.roc_auc_score(y, predict_prob[:, 1])<br> print(“AUC:{}”.format(AUC))<br> print(“ACC:{}”.format(metrics.accuracy_score(y, predicted)))<br> print(“MCC:{}”.format(metrics.matthews_corrcoef(y, predicted)))<br> print(classification_report(y, predicted, labels&#x3D;label))<br> print(“confusion matrix\n”)<br> print(pd.crosstab(pd.Series(y, name&#x3D;’Actual’), pd.Series(predicted, name&#x3D;’Predicted’)))</p>
</div></div></article><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/2022/06/18/%E9%98%85%E8%AF%BB%E8%AE%BA%E6%96%87%E7%9A%84%E6%96%B9%E6%B3%95/">阅读论文的方法</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">发表于</span><span class="post-meta-item__value">2022-06-18</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">更新于</span><span class="post-meta-item__value">2023-06-18</span></span></div></header><div class="post-body"><div class="post-excerpt"><p>一、方法整体流程<br>第一步：收集并整合相关资源<br>第二步：深入研究你认为与主题相关的任何资源<br>第三步：做笔记，对该领域理解的升华<br>二、详细阐述如何阅读一篇论文<br>第一遍：阅读标题、摘要、文中图表<br>第二遍：阅读引言、结论，掌握关键信息；并结合图表快速扫描文章其余的内容<br>第三遍：对论文进行整体阅读，但要跳过任何对你来说可能陌生的复杂的数学或技术公式。在此过程中，还可以跳过不理解或不熟悉的任何术语和术语<br>三、通过问自己问题来检测对论文的理解程度<br>1、论文的作者想要完成什么，或者已经完成了什么？<br>2、如果一篇论文介绍了一种新方法&#x2F;技术&#x2F;方法，那么该新方法的关键要素是什么?<br>3、论文中哪些内容对你有用?<br>4、你还想关注哪些参考文献?</p>
</div></div></article><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/2022/06/16/%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/">pytorch</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">发表于</span><span class="post-meta-item__value">2022-06-16</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">更新于</span><span class="post-meta-item__value">2023-06-16</span></span></div></header><div class="post-body"><div class="post-excerpt">
        <h2 id="实操"   >
          <a href="#实操" class="heading-link"><i class="fas fa-link"></i></a><a href="#实操" class="headerlink" title="实操"></a>实操</h2>
      <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">x = torch.arange(<span class="number">12</span>)</span><br><span class="line">x.shape</span><br><span class="line">x.numel() <span class="comment"># numble</span></span><br><span class="line">x = x.reshape(<span class="number">3</span>,<span class="number">4</span>) <span class="comment"># 不改变个数和值，只改变形状</span></span><br><span class="line"></span><br><span class="line">torch.zeros((<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>))</span><br><span class="line">torch.ones((<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>))</span><br><span class="line">torch.tensor([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>],[<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>],[<span class="number">0</span>,<span class="number">9</span>,<span class="number">8</span>,<span class="number">6</span>]]) <span class="comment"># 创建一个指定的</span></span><br><span class="line"></span><br><span class="line">x = torch.tensor([<span class="number">1.0</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>])</span><br><span class="line">y = torch.tensor([<span class="number">3</span>,<span class="number">5</span>,<span class="number">7</span>,<span class="number">9</span>])</span><br><span class="line">x + y, x - y, x * y, x / y, x**y  <span class="comment"># 所有的运算都是按照元素进行计算的</span></span><br><span class="line"></span><br><span class="line">torch.exp(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 把多个张量连接起来</span></span><br><span class="line">x = torch.arange(<span class="number">12</span>, dtype=torch.float32).reshape((<span class="number">3</span>,<span class="number">4</span>))</span><br><span class="line">y = torch.tensor([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>],[<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>],[<span class="number">0</span>,<span class="number">9</span>,<span class="number">8</span>,<span class="number">6</span>]])</span><br><span class="line">torch.cat((x ,y), dim=<span class="number">0</span>), torch.cat((x , y), dim=<span class="number">1</span>)<span class="comment"># 0 是行，1 是列</span></span><br><span class="line"></span><br><span class="line"> <span class="comment"># 通过逻辑运算符构建二元张量</span></span><br><span class="line">x == y</span><br><span class="line"></span><br><span class="line"> <span class="comment"># 对张量中的所有元素进行求和会产生一个只有一个元素的张量</span></span><br><span class="line">x.<span class="built_in">sum</span>()  <span class="comment"># 对x中的所有元素求和</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 即使形状不同，我们可以通过广播机制来执行</span></span><br><span class="line">a = torch.arange(<span class="number">3</span>).reshape((<span class="number">3</span>,<span class="number">1</span>))</span><br><span class="line">b = torch.arange(<span class="number">2</span>).reshape((<span class="number">1</span>,<span class="number">2</span>))</span><br><span class="line">a + b</span><br><span class="line"></span><br><span class="line"><span class="comment"># 访问元素</span></span><br><span class="line">x[-<span class="number">1</span>] <span class="comment"># 选择最后一行</span></span><br><span class="line">x[<span class="number">1</span>;<span class="number">3</span>] <span class="comment"># 选择第二行，第三行元素</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过制定索引写值</span></span><br><span class="line">x[<span class="number">1</span>, <span class="number">2</span>] = <span class="number">9</span>  <span class="comment">#把1行2列的值写为9</span></span><br><span class="line">x[<span class="number">0</span>:<span class="number">2</span>, :] = <span class="number">12</span> <span class="comment"># 把0-1行的全部列写为12 按区域赋值</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 转换为numpy 张量</span></span><br><span class="line">a = x.numpy()</span><br><span class="line">b = torch.tensor(a)</span><br><span class="line"><span class="built_in">type</span>(a),<span class="built_in">type</span>(b)</span><br><span class="line">    </span><br><span class="line"> <span class="comment"># 将大小为1的张量转换为python标量</span></span><br><span class="line"></span><br><span class="line">a = torch.tensor([<span class="number">3</span> ,<span class="number">5</span>])</span><br><span class="line">a, a,item(), <span class="built_in">float</span>(a), <span class="built_in">int</span>(a)</span><br></pre></td></tr></table></div></figure>
</div></div></article><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/2022/06/16/%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/">pytorch-数据预处理</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">发表于</span><span class="post-meta-item__value">2022-06-16</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">更新于</span><span class="post-meta-item__value">2023-06-16</span></span></div></header><div class="post-body"><div class="post-excerpt">
        <h2 id="数据预处理"   >
          <a href="#数据预处理" class="heading-link"><i class="fas fa-link"></i></a><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h2>
      <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#创建一个人工数据集，并存储在csv(逗号分隔值)文件</span></span><br><span class="line"><span class="keyword">import</span> os </span><br><span class="line">os.makedirs(os.path.join(<span class="string">&#x27;..&#x27;</span>,<span class="string">&#x27;data&#x27;</span>), exist_ok=<span class="literal">True</span>)</span><br><span class="line">data_file = os.path.join(<span class="string">&#x27;..&#x27;</span>,<span class="string">&#x27;data&#x27;</span>,<span class="string">&#x27;house_tiny.csv&#x27;</span>)</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(data_file,<span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(<span class="string">&#x27;numrooms,aller,price\n&#x27;</span>)</span><br><span class="line">    f.write(<span class="string">&#x27;NA,pave,127500\n&#x27;</span>)</span><br><span class="line">    f.write(<span class="string">&#x27;2,NA,10600\n&#x27;</span>)</span><br><span class="line">    f.write(<span class="string">&#x27;4,NA,178100\n&#x27;</span>)</span><br><span class="line">    f.write(<span class="string">&#x27;NA,NA,140000\n&#x27;</span>)</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 从csv 文件读取原始数据集</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"> </span><br><span class="line">data = pd.read_csv(data_file)</span><br><span class="line"><span class="built_in">print</span>(data)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 为了处理缺失的数据，典型的方法包括 插值和删除，这里，我们将考虑插值</span></span><br><span class="line">inputs, outputs = data.iloc[:,<span class="number">0</span>:<span class="number">2</span>], data.iloc[:, <span class="number">2</span>]</span><br><span class="line">inputs = inputs.fillna(inputs.mean())</span><br><span class="line"><span class="built_in">print</span>(inputs)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对于inputs中的类别值或离散值，我们将“NaN&quot;视为一个类别</span></span><br><span class="line">inputs = pd.get_dummies(inputs, dummy_na=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(inputs)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch </span><br><span class="line">x, y = torch.tensor(inputs.values), torch.tensor(outputs.values)</span><br><span class="line">x, y </span><br></pre></td></tr></table></div></figure></div></div></article></section><nav class="paginator"><div class="paginator-inner"><span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/2/"><i class="fas fa-angle-right"></i></a></div></nav></div></div><div class="sidebar-wrap" id="sidebar-wrap"><aside class="sidebar" id="sidebar"><section class="sidebar-toc hide"></section><!-- ov = overview--><section class="sidebar-ov"><div class="sidebar-ov-author"><div class="sidebar-ov-author__avatar"><img class="sidebar-ov-author__avatar_img" src="/assets/tx.jpg" alt="avatar"></div><p class="sidebar-ov-author__text">漏勺的加油站</p></div><div class="sidebar-ov-state"><a class="sidebar-ov-state-item sidebar-ov-state-item--posts" href="/archives/"><div class="sidebar-ov-state-item__count">23</div><div class="sidebar-ov-state-item__name">归档</div></a><a class="sidebar-ov-state-item sidebar-ov-state-item--categories" href="/categories/"><div class="sidebar-ov-state-item__count">10</div><div class="sidebar-ov-state-item__name">分类</div></a><a class="sidebar-ov-state-item sidebar-ov-state-item--tags" href="/tags/"><div class="sidebar-ov-state-item__count">6</div><div class="sidebar-ov-state-item__name">标签</div></a></div><div class="sidebar-ov-cc"><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en" target="_blank" rel="noopener" data-popover="知识共享许可协议" data-popover-pos="up"><img src="/images/cc-by-nc-sa.svg"></a></div></section></aside></div><div class="clearfix"></div></div></main><footer class="footer" id="footer"><div class="footer-inner"><div><span>Copyright © 2023</span><span class="footer__icon"><i class="fas fa-heart"></i></span><span>小勺</span></div></div></footer><div class="loading-bar" id="loading-bar"><div class="loading-bar__progress"></div></div><div class="back2top" id="back2top"><span class="back2top__icon"><i class="fas fa-rocket"></i></span></div></div><script src="https://cdn.jsdelivr.net/npm/jquery@v3.4.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.2/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.2/velocity.ui.min.js"></script><script src="/js/utils.js?v=2.8.0"></script><script src="/js/stun-boot.js?v=2.8.0"></script><script src="/js/scroll.js?v=2.8.0"></script><script src="/js/header.js?v=2.8.0"></script><script src="/js/sidebar.js?v=2.8.0"></script><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"live2d-widget-model-miku"},"display":{"position":"left","width":150,"height":190,"hOffset":50,"vOffset":-5},"mobile":{"show":false,"scale":0.5},"react":{"opacityDefault":0.7,"opacityOnHover":0.8},"log":false});</script></body></html>
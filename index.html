<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black"><link rel="icon" href="/images/icons/favicon-16x16.png?v=2.8.0" type="image/png" sizes="16x16"><link rel="icon" href="/images/icons/favicon-32x32.png?v=2.8.0" type="image/png" sizes="32x32"><meta property="og:type" content="website">
<meta property="og:title" content="漏勺的加油站">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="漏勺的加油站">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="小勺">
<meta name="twitter:card" content="summary"><title>漏勺的加油站</title><link ref="canonical" href="http://example.com/index.html"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.12.1/css/all.min.css" type="text/css"><link rel="stylesheet" href="/css/index.css?v=2.8.0"><link rel="stylesheet" href="css/custom.css"><script>var Stun = window.Stun || {};
var CONFIG = {
  root: '/',
  algolia: undefined,
  assistSearch: undefined,
  fontIcon: {"prompt":{"success":"fas fa-check-circle","info":"fas fa-arrow-circle-right","warning":"fas fa-exclamation-circle","error":"fas fa-times-circle"},"copyBtn":"fas fa-copy"},
  sidebar: {"offsetTop":"20px","tocMaxDepth":6},
  header: {"enable":true,"showOnPost":true,"scrollDownIcon":false},
  postWidget: {"endText":true},
  nightMode: {"enable":true},
  back2top: {"enable":true},
  codeblock: {"style":"default","highlight":"light","wordWrap":false},
  reward: false,
  fancybox: false,
  zoomImage: {"gapAside":"20px"},
  galleryWaterfall: undefined,
  lazyload: false,
  pjax: undefined,
  externalLink: {"icon":{"enable":true,"name":"fas fa-external-link-alt"}},
  shortcuts: undefined,
  prompt: {"copyButton":"复制","copySuccess":"复制成功","copyError":"复制失败"},
  sourcePath: {"js":"js","css":"css","images":"images"},
};

window.CONFIG = CONFIG;</script><meta name="generator" content="Hexo 6.0.0"></head><body><div class="container" id="container"><header class="header" id="header"><div class="header-inner"><nav class="header-nav header-nav--fixed"><div class="header-nav-inner"><div class="header-nav-menubtn"><i class="fas fa-bars"></i></div><div class="header-nav-menu"><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/"><span class="header-nav-menu-item__icon"><i class="fas fa-home"></i></span><span class="header-nav-menu-item__text">首页</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/archives/"><span class="header-nav-menu-item__icon"><i class="fas fa-folder-open"></i></span><span class="header-nav-menu-item__text">归档</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/categories/"><span class="header-nav-menu-item__icon"><i class="fas fa-layer-group"></i></span><span class="header-nav-menu-item__text">分类</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/tags/"><span class="header-nav-menu-item__icon"><i class="fas fa-tags"></i></span><span class="header-nav-menu-item__text">标签</span></a></div></div><div class="header-nav-mode"><div class="mode"><div class="mode-track"><span class="mode-track-moon"></span><span class="mode-track-sun"></span></div><div class="mode-thumb"></div></div></div></div></nav><div class="header-banner"></div></div></header><main class="main" id="main"><div class="main-inner"><div class="content-wrap" id="content-wrap"><div class="content content-home" id="content"><section class="postlist"><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/2023/07/07/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/">生成模型</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">发表于</span><span class="post-meta-item__value">2023-07-07</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">更新于</span><span class="post-meta-item__value">2023-07-07</span></span></div></header><div class="post-body"><div class="post-excerpt">
        <h1 id="生成建模的兴起"   >
          <a href="#生成建模的兴起" class="heading-link"><i class="fas fa-link"></i></a><a href="#生成建模的兴起" class="headerlink" title="生成建模的兴起"></a>生成建模的兴起</h1>
      <p>直到最近，判别建模一直是机器学习方法取得大多数进展的驱动力。这是因为对于任何判别问题，相应的生成建模问题通常更难解决。例如，训练一个模型来预测一幅画是否出自梵高，要比训练一个模型从头开始生成一幅梵高风格的画要容易得多。同样，训练一个模型来预测一页文本是否出自查尔斯·狄更斯之手，要比构建一个模型来生成一组狄更斯风格的段落要容易得多。直到最近，大多数生成性挑战还是遥不可及，许多人怀疑它们能否得到解决。创造力被认为是一种纯粹的人类能力，人工智能无法与之匹敌。</p>
<p>除了更容易解决之外，判别式建模在历史上比生成式建模更容易应用于跨行业的实际问题。例如，医生可能会受益于预测给定视网膜图像是否显示青光眼迹象的模型，但不会受益于可以生成眼睛后部新图片的模型。</p>
<p>然而，随着提供针对特定业务问题的生成服务的公司激增，这种情况也开始发生变化。例如，现在可以访问 API 生成给定特定主题的原始博客文章，在您想要的任何设置中生成各种产品图像，或者编写社交媒体内容和广告文案以匹配您的品牌和目标信息。生成式人工智能在游戏设计和电影摄影等行业也有明显的积极应用，在这些行业中，经过训练以输出视频和音乐生成的模型开始增加价值。</p>

        <h1 id="什么是生成模型？"   >
          <a href="#什么是生成模型？" class="heading-link"><i class="fas fa-link"></i></a><a href="#什么是生成模型？" class="headerlink" title="什么是生成模型？"></a>什么是生成模型？</h1>
      <p>定义：生成建模是机器学习的一个分支，涉及训练模型以生成类似于给定数据集的新数据。<br>为了构建生成模型，我们需要一个由我们尝试生成的实体的许多示例组成的数据集。这被称为训练数据，一个这样的数据点被称为观察。<br>每个观察包括许多特征。对于图像生成问题，特征通常是单个像素值；对于文本生成问题，特征可以是单个单词或字母组。我们的目标是构建一个模型，该模型可以生成新的特征集，这些特征集看起来就像是使用与原始数据相同的规则创建的。从概念上讲，对于图像生成来说，这是一项极其困难的任务，考虑到可以分配单个像素值的方式有很多种，而构成我们试图生成的实体图像的此类排列的数量相对较少<br>一个生成器模型还必须是概率性的而不是确定性的，因为我们希望能够对输出的许多不同变化进行采样，而不是每次都获得相同的输出。如果我们的模型只是一个固定的计算，比如取训练数据集中每个像素的平均值，那么它就不是生成式的。一个生成模型必须包含影响模型生成的单个样本的随机成分。<br>换句话说，我们可以想象存在某种未知的概率分布，它可以解释为什么有些图像很可能在训练数据集中找到，而另一些图像则不然。我们的工作是建立一个模型，尽可能地模仿这种分布，然后从中抽样以生成新的、不同的观察结果，这些观察结果看起来就像它们可以包含在原始训练集中一样。</p>

        <h1 id="生成模型类型"   >
          <a href="#生成模型类型" class="heading-link"><i class="fas fa-link"></i></a><a href="#生成模型类型" class="headerlink" title="生成模型类型"></a>生成模型类型</h1>
      <ul>
<li><p>显式建模密度函数，但以某种方式约束模型，以便密度函数易于处理（即可以计算）。</p>
</li>
<li><p>显式建模密度函数的易处理近似值</p>
</li>
<li><p>通过直接生成数据的随机过程，对密度函数进行隐式建模。</p>
</li>
</ul>

        <h1 id="概率论相关知识"   >
          <a href="#概率论相关知识" class="heading-link"><i class="fas fa-link"></i></a><a href="#概率论相关知识" class="headerlink" title="概率论相关知识"></a>概率论相关知识</h1>
      <ul>
<li>样本空间</li>
<li>概率密度函数</li>
<li>参数化建模</li>
<li>最大似然估计</li>
</ul>
</div></div></article><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/2023/06/29/%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B/">扩散模型</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">发表于</span><span class="post-meta-item__value">2023-06-29</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">更新于</span><span class="post-meta-item__value">2023-06-29</span></span></div></header><div class="post-body"><div class="post-excerpt">
        <h1 id="扩散模型"   >
          <a href="#扩散模型" class="heading-link"><i class="fas fa-link"></i></a><a href="#扩散模型" class="headerlink" title="扩散模型"></a>扩散模型</h1>
      <ol>
<li>Diffusion Model （扩散模型）一（DDPM）Denoising diffusion probalistic models<ul>
<li>前向加噪声步骤：通过增加T次高斯分布噪声，前向步骤为马尔可夫链，每个步骤仅仅与上一个步骤相关，实现将一张图片变为纯高斯噪声的过程。</li>
<li>反向还原噪声步骤：通过模型预估步骤1中增加噪声的逆向分布，从而最终实现从纯高斯噪声变为图片的步骤。</li>
<li>在DDPM中我们基于初始图像状态以及最终高斯噪声状态，通过贝叶斯公式以及多元高斯分布的散度公式，可以计算出每一步骤的逆向分布。之后继续重复上述对逆向分布的求解步骤，最终实现从纯高斯噪声，恢复到原始图片的步骤。</li>
</ul>
</li>
<li>Diffusion Model （扩散模型）解读系列二：(DDIM) denoising diffusion implicit models</li>
<li>Diffusion Model (扩散模型)系列三:CLIP Learning Transferable Visual Models From Natural Language Supervision</li>
</ol>
</div></div></article><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/2023/06/27/MUSIC/">MUSIC</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">发表于</span><span class="post-meta-item__value">2023-06-27</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">更新于</span><span class="post-meta-item__value">2023-06-28</span></span></div></header><div class="post-body"><div class="post-excerpt">
        <h1 id="音乐生成，理解"   >
          <a href="#音乐生成，理解" class="heading-link"><i class="fas fa-link"></i></a><a href="#音乐生成，理解" class="headerlink" title="音乐生成，理解"></a>音乐生成，理解</h1>
      
        <h2 id="音乐生成，是指从给定文本描述的情况下生成音乐作品的任务。"   >
          <a href="#音乐生成，是指从给定文本描述的情况下生成音乐作品的任务。" class="heading-link"><i class="fas fa-link"></i></a><a href="#音乐生成，是指从给定文本描述的情况下生成音乐作品的任务。" class="headerlink" title="音乐生成，是指从给定文本描述的情况下生成音乐作品的任务。"></a>音乐生成，是指从给定文本描述的情况下生成音乐作品的任务。</h2>
      <ul>
<li>音乐定义为不同频率音调的集合。</li>
<li>自动音乐的生成是一个在最少的人为干预下创作一首短曲的过程。</li>
</ul>

        <h2 id="建模"   >
          <a href="#建模" class="heading-link"><i class="fas fa-link"></i></a><a href="#建模" class="headerlink" title="建模"></a>建模</h2>
      <p>音乐生成要对长序列进行建模，与语音不同，音乐需要使用全频谱，这意味着要以更高的速率对信号进行采样，即音乐录音的标准采样率为44.1KHZ或48KHZ，而语音的采样率为16KHZ。</p>

        <h2 id="音乐的构成要素"   >
          <a href="#音乐的构成要素" class="heading-link"><i class="fas fa-link"></i></a><a href="#音乐的构成要素" class="headerlink" title="音乐的构成要素"></a>音乐的构成要素</h2>
      <ul>
<li>音符（Note）:一个键发出的声音叫做音符</li>
<li>和弦（Chords）:由两个活多个健同时产生的声音称为和弦，一般来说，大多数和弦至少包含3个关键音</li>
<li>八度（Octave）:重复的模式称为八度，每个八度音阶包含7个白键和5个黑键。</li>
</ul>

        <h2 id="深度学习架构"   >
          <a href="#深度学习架构" class="heading-link"><i class="fas fa-link"></i></a><a href="#深度学习架构" class="headerlink" title="深度学习架构"></a>深度学习架构</h2>
      <ol>
<li>WaveNet 主要目标是根据原始数据分布生成新的样本，即给定一个系列样本，试图预测下一个样本。</li>
<li>LSTM 循环神经网络的是一个变种，它能够捕获输入序列中的长期依赖关系，在语音识别，文本摘要，视频分类等序列建模任务中有着广泛的应用。</li>
</ol>

        <h2 id="目前主流模型s"   >
          <a href="#目前主流模型s" class="heading-link"><i class="fas fa-link"></i></a><a href="#目前主流模型s" class="headerlink" title="目前主流模型s"></a>目前主流模型s</h2>
      <ol>
<li>MUSIC LM</li>
<li>SingSong</li>
<li>AudioLDM</li>
<li>MouSai</li>
</ol>

        <h1 id="音乐的理解"   >
          <a href="#音乐的理解" class="heading-link"><i class="fas fa-link"></i></a><a href="#音乐的理解" class="headerlink" title="音乐的理解"></a>音乐的理解</h1>
      <ol>
<li>技术理解</li>
<li>情绪理解</li>
</ol>
</div></div></article><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/2023/06/20/%E8%87%AA%E5%8A%A8%E6%B1%82%E5%AF%BC/">自动求导</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">发表于</span><span class="post-meta-item__value">2023-06-20</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">更新于</span><span class="post-meta-item__value">2023-06-20</span></span></div></header><div class="post-body"><div class="post-excerpt"><h1 id="自动求导"   >
          <a href="#自动求导" class="heading-link"><i class="fas fa-link"></i></a><a href="#自动求导" class="headerlink" title="自动求导"></a>自动求导</h1>
      <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">x = torch.arange(<span class="number">4.0</span>)  <span class="comment"># 关于列向量x求导，创建一个x四维向量</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 在我们计算y关于x的梯度之前，我们需要一个地方来存储梯度</span></span><br><span class="line">x.requires_grad_(<span class="literal">True</span>) <span class="comment"># 等价与x = torch.arange(4.0,requires_grad=True)</span></span><br><span class="line">x.grad <span class="comment"># 默认值是none</span></span><br></pre></td></tr></table></div></figure></div><div class="post-readmore"><a class="post-readmore__link" href="/2023/06/20/%E8%87%AA%E5%8A%A8%E6%B1%82%E5%AF%BC/"><span class="post-readmore__text">阅读全文</span><span class="post-readmore__icon"><i class="fas fa-long-arrow-alt-right"></i></span></a></div></div></article><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/2023/02/21/Softmax/">Softmax</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">发表于</span><span class="post-meta-item__value">2023-02-21</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">更新于</span><span class="post-meta-item__value">2023-06-21</span></span></div></header><div class="post-body"><div class="post-excerpt"><h2 id="回归和分类的区别"   >
          <a href="#回归和分类的区别" class="heading-link"><i class="fas fa-link"></i></a><a href="#回归和分类的区别" class="headerlink" title="回归和分类的区别"></a>回归和分类的区别</h2>
      <ul>
<li>回归估计一个连续值<ul>
<li>单连续数值输出</li>
<li>自然区间R</li>
<li>跟真实值的区别作为损失</div><div class="post-readmore"><a class="post-readmore__link" href="/2023/02/21/Softmax/"><span class="post-readmore__text">阅读全文</span><span class="post-readmore__icon"><i class="fas fa-long-arrow-alt-right"></i></span></a></div></div></article><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/2023/02/20/%E5%9F%BA%E7%A1%80%E4%BC%98%E5%8C%96/">基础优化</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">发表于</span><span class="post-meta-item__value">2023-02-20</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">更新于</span><span class="post-meta-item__value">2023-06-20</span></span></div></header><div class="post-body"><div class="post-excerpt"><h2 id="梯度下降"   >
          <a href="#梯度下降" class="heading-link"><i class="fas fa-link"></i></a><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h2>
      <ul>
<li>挑选一个初始值w0</li>
<li>重复迭代参数t &#x3D; 1,2,3<br>wt &#x3D; w(t-1)- n ∂l&#x2F;∂w(t-1)</li>
<li>沿梯度方向将增加损失函数值</li>
<li>学习率：步长的超参数 n</div><div class="post-readmore"><a class="post-readmore__link" href="/2023/02/20/%E5%9F%BA%E7%A1%80%E4%BC%98%E5%8C%96/"><span class="post-readmore__text">阅读全文</span><span class="post-readmore__icon"><i class="fas fa-long-arrow-alt-right"></i></span></a></div></div></article><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/2023/02/20/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/">线性回归</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">发表于</span><span class="post-meta-item__value">2023-02-20</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">更新于</span><span class="post-meta-item__value">2023-06-20</span></span></div></header><div class="post-body"><div class="post-excerpt"><h2 id="线性模型"   >
          <a href="#线性模型" class="heading-link"><i class="fas fa-link"></i></a><a href="#线性模型" class="headerlink" title="线性模型"></a>线性模型</h2>
      <ul>
<li>给定n维输入 x &#x3D; [x1,x2,…,xn]T</li>
<li>线性模型有一个n维权重和一个标量偏差 W &#x3D; [w1,w2,…,wn]T,b</li>
<li>输出是输入的加权和  y&#x3D;w1x1 + w2x2 + … + wnxn + b</li>
<li>向量版本： y &#x3D; &lt;w,x&gt; + b </li>
<li>b 为标量的偏差</div><div class="post-readmore"><a class="post-readmore__link" href="/2023/02/20/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"><span class="post-readmore__text">阅读全文</span><span class="post-readmore__icon"><i class="fas fa-long-arrow-alt-right"></i></span></a></div></div></article><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/2023/02/15/Prototypical%20Networks%20for%20Few-shot%20Learning/">Prototypical Networks for Few-shot Learning</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">发表于</span><span class="post-meta-item__value">2023-02-15</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">更新于</span><span class="post-meta-item__value">2023-06-20</span></span></div></header><div class="post-body"><div class="post-excerpt"><p>1.原型网络的思想：将每个类别中的样例数据映射到一个空间当中，并且提取他们的“均值”来表示为该类的原型（prototype）。使用欧几里得距离作为距离度量，训练使得本类别数据到本类原形表示的距离为最近，到其他类原形表示的距离较远。测试时，对测试数据到各个类别的原形数据的距离做softmax，来判断测试数据的类别标签。</p></div><div class="post-readmore"><a class="post-readmore__link" href="/2023/02/15/Prototypical%20Networks%20for%20Few-shot%20Learning/"><span class="post-readmore__text">阅读全文</span><span class="post-readmore__icon"><i class="fas fa-long-arrow-alt-right"></i></span></a></div></div></article><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/2023/02/11/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/">线性代数</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">发表于</span><span class="post-meta-item__value">2023-02-11</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">更新于</span><span class="post-meta-item__value">2023-06-20</span></span></div></header><div class="post-body"><div class="post-excerpt"><figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建一个矩阵</span></span><br><span class="line">A = torch.arange(<span class="number">20</span>).reshape(<span class="number">5</span>, <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 矩阵的转置</span></span><br><span class="line">A.T</span><br></pre></td></tr></table></div></figure></div><div class="post-readmore"><a class="post-readmore__link" href="/2023/02/11/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/"><span class="post-readmore__text">阅读全文</span><span class="post-readmore__icon"><i class="fas fa-long-arrow-alt-right"></i></span></a></div></div></article><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/2023/02/10/%E5%AD%97%E8%8A%82%E8%B7%B3%E5%8A%A8/">SEGMENT-LEVEL METRIC LEARNING FOR FEW-SHOT BIOACOUSTIC EVENT DETECTION</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">发表于</span><span class="post-meta-item__value">2023-02-10</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">更新于</span><span class="post-meta-item__value">2023-06-20</span></span></div></header><div class="post-body"><div class="post-excerpt"><p>小样本生物声学事件检测是一项检测给定几个例子的新声音的发生时间的任务。以前的方法采用度量学习，用不同声音类别的标记部分建立一个潜在的空间，也就是所谓的正面事件。在这项研究中，我们提出了一个段级的小样本学习框架，在模型优化过程中同时利用正面和负面事件。用负面事件进行训练，其数量比正面事件大，可以提高模型的泛化能力。此外，在训练过程中，我们在验证集上使用过渡性推理，以更好地适应新的类别。我们通过对输入特征、训练数据和超参数的不同设置对我们提出的方法进行了消融研究。我们最终的系统在DCASE2022挑战任务5（DCASE2022-T5）验证集上取得了62.73的F值，比基线原型网络34.02的性能要好得多。使用建议的方法，我们提交的系统在DCASE2022-T5中排名第二。本文的代码是完全开放的1</p></div><div class="post-readmore"><a class="post-readmore__link" href="/2023/02/10/%E5%AD%97%E8%8A%82%E8%B7%B3%E5%8A%A8/"><span class="post-readmore__text">阅读全文</span><span class="post-readmore__icon"><i class="fas fa-long-arrow-alt-right"></i></span></a></div></div></article></section><nav class="paginator"><div class="paginator-inner"><span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/2/"><i class="fas fa-angle-right"></i></a></div></nav></div></div><div class="sidebar-wrap" id="sidebar-wrap"><aside class="sidebar" id="sidebar"><section class="sidebar-toc hide"></section><!-- ov = overview--><section class="sidebar-ov"><div class="sidebar-ov-author"><div class="sidebar-ov-author__avatar"><img class="sidebar-ov-author__avatar_img" src="/assets/tx.jpg" alt="avatar"></div><p class="sidebar-ov-author__text">漏勺的加油站</p></div><div class="sidebar-ov-state"><a class="sidebar-ov-state-item sidebar-ov-state-item--posts" href="/archives/"><div class="sidebar-ov-state-item__count">30</div><div class="sidebar-ov-state-item__name">归档</div></a><a class="sidebar-ov-state-item sidebar-ov-state-item--categories" href="/categories/"><div class="sidebar-ov-state-item__count">12</div><div class="sidebar-ov-state-item__name">分类</div></a><a class="sidebar-ov-state-item sidebar-ov-state-item--tags" href="/tags/"><div class="sidebar-ov-state-item__count">8</div><div class="sidebar-ov-state-item__name">标签</div></a></div><div class="sidebar-ov-cc"><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en" target="_blank" rel="noopener" data-popover="知识共享许可协议" data-popover-pos="up"><img src="/images/cc-by-nc-sa.svg"></a></div></section></aside></div><div class="clearfix"></div></div></main><footer class="footer" id="footer"><div class="footer-inner"><div><span>Copyright © 2023</span><span class="footer__icon"><i class="fas fa-heart"></i></span><span>小勺</span></div></div></footer><div class="loading-bar" id="loading-bar"><div class="loading-bar__progress"></div></div><div class="back2top" id="back2top"><span class="back2top__icon"><i class="fas fa-rocket"></i></span></div></div><script src="https://cdn.jsdelivr.net/npm/jquery@v3.4.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.2/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.2/velocity.ui.min.js"></script><script src="/js/utils.js?v=2.8.0"></script><script src="/js/stun-boot.js?v=2.8.0"></script><script src="/js/scroll.js?v=2.8.0"></script><script src="/js/header.js?v=2.8.0"></script><script src="/js/sidebar.js?v=2.8.0"></script><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"live2d-widget-model-miku"},"display":{"position":"left","width":150,"height":190,"hOffset":50,"vOffset":-5},"mobile":{"show":false,"scale":0.5},"react":{"opacityDefault":0.7,"opacityOnHover":0.8},"log":false});</script></body></html>
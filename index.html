<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black"><link rel="icon" href="/images/icons/favicon-16x16.png?v=2.8.0" type="image/png" sizes="16x16"><link rel="icon" href="/images/icons/favicon-32x32.png?v=2.8.0" type="image/png" sizes="32x32"><meta property="og:type" content="website">
<meta property="og:title" content="漏勺的加油站">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="漏勺的加油站">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="小勺">
<meta name="twitter:card" content="summary"><title>漏勺的加油站</title><link ref="canonical" href="http://example.com/index.html"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.12.1/css/all.min.css" type="text/css"><link rel="stylesheet" href="/css/index.css?v=2.8.0"><link rel="stylesheet" href="css/custom.css"><script>var Stun = window.Stun || {};
var CONFIG = {
  root: '/',
  algolia: undefined,
  assistSearch: undefined,
  fontIcon: {"prompt":{"success":"fas fa-check-circle","info":"fas fa-arrow-circle-right","warning":"fas fa-exclamation-circle","error":"fas fa-times-circle"},"copyBtn":"fas fa-copy"},
  sidebar: {"offsetTop":"20px","tocMaxDepth":6},
  header: {"enable":true,"showOnPost":true,"scrollDownIcon":false},
  postWidget: {"endText":true},
  nightMode: {"enable":true},
  back2top: {"enable":true},
  codeblock: {"style":"default","highlight":"light","wordWrap":false},
  reward: false,
  fancybox: false,
  zoomImage: {"gapAside":"20px"},
  galleryWaterfall: undefined,
  lazyload: false,
  pjax: undefined,
  externalLink: {"icon":{"enable":true,"name":"fas fa-external-link-alt"}},
  shortcuts: undefined,
  prompt: {"copyButton":"复制","copySuccess":"复制成功","copyError":"复制失败"},
  sourcePath: {"js":"js","css":"css","images":"images"},
};

window.CONFIG = CONFIG;</script><meta name="generator" content="Hexo 6.0.0"></head><body><div class="container" id="container"><header class="header" id="header"><div class="header-inner"><nav class="header-nav header-nav--fixed"><div class="header-nav-inner"><div class="header-nav-menubtn"><i class="fas fa-bars"></i></div><div class="header-nav-menu"><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/"><span class="header-nav-menu-item__icon"><i class="fas fa-home"></i></span><span class="header-nav-menu-item__text">首页</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/archives/"><span class="header-nav-menu-item__icon"><i class="fas fa-folder-open"></i></span><span class="header-nav-menu-item__text">归档</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/categories/"><span class="header-nav-menu-item__icon"><i class="fas fa-layer-group"></i></span><span class="header-nav-menu-item__text">分类</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/tags/"><span class="header-nav-menu-item__icon"><i class="fas fa-tags"></i></span><span class="header-nav-menu-item__text">标签</span></a></div></div><div class="header-nav-mode"><div class="mode"><div class="mode-track"><span class="mode-track-moon"></span><span class="mode-track-sun"></span></div><div class="mode-thumb"></div></div></div></div></nav><div class="header-banner"></div></div></header><main class="main" id="main"><div class="main-inner"><div class="content-wrap" id="content-wrap"><div class="content content-home" id="content"><section class="postlist"><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/2023/06/21/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/">损失函数</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">发表于</span><span class="post-meta-item__value">2023-06-21</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">更新于</span><span class="post-meta-item__value">2023-06-21</span></span></div></header><div class="post-body"><div class="post-excerpt"></div></div></article><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/2023/06/20/%E8%87%AA%E5%8A%A8%E6%B1%82%E5%AF%BC/">自动求导</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">发表于</span><span class="post-meta-item__value">2023-06-20</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">更新于</span><span class="post-meta-item__value">2023-06-20</span></span></div></header><div class="post-body"><div class="post-excerpt"><h1 id="自动求导"   >
          <a href="#自动求导" class="heading-link"><i class="fas fa-link"></i></a><a href="#自动求导" class="headerlink" title="自动求导"></a>自动求导</h1>
      <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">x = torch.arange(<span class="number">4.0</span>)  <span class="comment"># 关于列向量x求导，创建一个x四维向量</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 在我们计算y关于x的梯度之前，我们需要一个地方来存储梯度</span></span><br><span class="line">x.requires_grad_(<span class="literal">True</span>) <span class="comment"># 等价与x = torch.arange(4.0,requires_grad=True)</span></span><br><span class="line">x.grad <span class="comment"># 默认值是none</span></span><br></pre></td></tr></table></div></figure></div><div class="post-readmore"><a class="post-readmore__link" href="/2023/06/20/%E8%87%AA%E5%8A%A8%E6%B1%82%E5%AF%BC/"><span class="post-readmore__text">阅读全文</span><span class="post-readmore__icon"><i class="fas fa-long-arrow-alt-right"></i></span></a></div></div></article><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/2023/02/21/Softmax/">Softmax</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">发表于</span><span class="post-meta-item__value">2023-02-21</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">更新于</span><span class="post-meta-item__value">2023-06-21</span></span></div></header><div class="post-body"><div class="post-excerpt"><h2 id="回归和分类的区别"   >
          <a href="#回归和分类的区别" class="heading-link"><i class="fas fa-link"></i></a><a href="#回归和分类的区别" class="headerlink" title="回归和分类的区别"></a>回归和分类的区别</h2>
      <ul>
<li>回归估计一个连续值<ul>
<li>单连续数值输出</li>
<li>自然区间R</li>
<li>跟真实值的区别作为损失</div><div class="post-readmore"><a class="post-readmore__link" href="/2023/02/21/Softmax/"><span class="post-readmore__text">阅读全文</span><span class="post-readmore__icon"><i class="fas fa-long-arrow-alt-right"></i></span></a></div></div></article><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/2023/02/20/%E5%9F%BA%E7%A1%80%E4%BC%98%E5%8C%96/">基础优化</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">发表于</span><span class="post-meta-item__value">2023-02-20</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">更新于</span><span class="post-meta-item__value">2023-06-20</span></span></div></header><div class="post-body"><div class="post-excerpt"><h2 id="梯度下降"   >
          <a href="#梯度下降" class="heading-link"><i class="fas fa-link"></i></a><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h2>
      <ul>
<li>挑选一个初始值w0</li>
<li>重复迭代参数t &#x3D; 1,2,3<br>wt &#x3D; w(t-1)- n ∂l&#x2F;∂w(t-1)</li>
<li>沿梯度方向将增加损失函数值</li>
<li>学习率：步长的超参数 n</div><div class="post-readmore"><a class="post-readmore__link" href="/2023/02/20/%E5%9F%BA%E7%A1%80%E4%BC%98%E5%8C%96/"><span class="post-readmore__text">阅读全文</span><span class="post-readmore__icon"><i class="fas fa-long-arrow-alt-right"></i></span></a></div></div></article><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/2023/02/20/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/">线性回归</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">发表于</span><span class="post-meta-item__value">2023-02-20</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">更新于</span><span class="post-meta-item__value">2023-06-20</span></span></div></header><div class="post-body"><div class="post-excerpt"><h2 id="线性模型"   >
          <a href="#线性模型" class="heading-link"><i class="fas fa-link"></i></a><a href="#线性模型" class="headerlink" title="线性模型"></a>线性模型</h2>
      <ul>
<li>给定n维输入 x &#x3D; [x1,x2,…,xn]T</li>
<li>线性模型有一个n维权重和一个标量偏差 W &#x3D; [w1,w2,…,wn]T,b</li>
<li>输出是输入的加权和  y&#x3D;w1x1 + w2x2 + … + wnxn + b</li>
<li>向量版本： y &#x3D; &lt;w,x&gt; + b </li>
<li>b 为标量的偏差</div><div class="post-readmore"><a class="post-readmore__link" href="/2023/02/20/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"><span class="post-readmore__text">阅读全文</span><span class="post-readmore__icon"><i class="fas fa-long-arrow-alt-right"></i></span></a></div></div></article><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/2023/02/15/Prototypical%20Networks%20for%20Few-shot%20Learning/">Prototypical Networks for Few-shot Learning</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">发表于</span><span class="post-meta-item__value">2023-02-15</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">更新于</span><span class="post-meta-item__value">2023-06-20</span></span></div></header><div class="post-body"><div class="post-excerpt"><p>1.原型网络的思想：将每个类别中的样例数据映射到一个空间当中，并且提取他们的“均值”来表示为该类的原型（prototype）。使用欧几里得距离作为距离度量，训练使得本类别数据到本类原形表示的距离为最近，到其他类原形表示的距离较远。测试时，对测试数据到各个类别的原形数据的距离做softmax，来判断测试数据的类别标签。</p></div><div class="post-readmore"><a class="post-readmore__link" href="/2023/02/15/Prototypical%20Networks%20for%20Few-shot%20Learning/"><span class="post-readmore__text">阅读全文</span><span class="post-readmore__icon"><i class="fas fa-long-arrow-alt-right"></i></span></a></div></div></article><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/2023/02/11/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/">线性代数</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">发表于</span><span class="post-meta-item__value">2023-02-11</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">更新于</span><span class="post-meta-item__value">2023-06-20</span></span></div></header><div class="post-body"><div class="post-excerpt"><figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建一个矩阵</span></span><br><span class="line">A = torch.arange(<span class="number">20</span>).reshape(<span class="number">5</span>, <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 矩阵的转置</span></span><br><span class="line">A.T</span><br></pre></td></tr></table></div></figure></div><div class="post-readmore"><a class="post-readmore__link" href="/2023/02/11/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/"><span class="post-readmore__text">阅读全文</span><span class="post-readmore__icon"><i class="fas fa-long-arrow-alt-right"></i></span></a></div></div></article><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/2023/02/10/%E5%AD%97%E8%8A%82%E8%B7%B3%E5%8A%A8/">SEGMENT-LEVEL METRIC LEARNING FOR FEW-SHOT BIOACOUSTIC EVENT DETECTION</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">发表于</span><span class="post-meta-item__value">2023-02-10</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">更新于</span><span class="post-meta-item__value">2023-06-20</span></span></div></header><div class="post-body"><div class="post-excerpt"><p>小样本生物声学事件检测是一项检测给定几个例子的新声音的发生时间的任务。以前的方法采用度量学习，用不同声音类别的标记部分建立一个潜在的空间，也就是所谓的正面事件。在这项研究中，我们提出了一个段级的小样本学习框架，在模型优化过程中同时利用正面和负面事件。用负面事件进行训练，其数量比正面事件大，可以提高模型的泛化能力。此外，在训练过程中，我们在验证集上使用过渡性推理，以更好地适应新的类别。我们通过对输入特征、训练数据和超参数的不同设置对我们提出的方法进行了消融研究。我们最终的系统在DCASE2022挑战任务5（DCASE2022-T5）验证集上取得了62.73的F值，比基线原型网络34.02的性能要好得多。使用建议的方法，我们提交的系统在DCASE2022-T5中排名第二。本文的代码是完全开放的1</p></div><div class="post-readmore"><a class="post-readmore__link" href="/2023/02/10/%E5%AD%97%E8%8A%82%E8%B7%B3%E5%8A%A8/"><span class="post-readmore__text">阅读全文</span><span class="post-readmore__icon"><i class="fas fa-long-arrow-alt-right"></i></span></a></div></div></article><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/2023/01/12/%E8%BF%9C%E7%A8%8B%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%93%BE%E6%8E%A5/">远程服务器链接</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">发表于</span><span class="post-meta-item__value">2023-01-12</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">更新于</span><span class="post-meta-item__value">2023-06-21</span></span></div></header><div class="post-body"><div class="post-excerpt"><ol>
<li>通过ipconfig&#x2F;ifcofig查看服务器的IP地址，如果没有反映可以sudo apt install net-too (是一个简单的网络管理工具，为了查看IP)，查看到IP地址以后可以在本机断ping一下IP地址，看一下是否能ping通</li>
<li>通过cat&#x2F;etc&#x2F;passwd 是机器的密码本，可以查看机器有什么用户</div><div class="post-readmore"><a class="post-readmore__link" href="/2023/01/12/%E8%BF%9C%E7%A8%8B%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%93%BE%E6%8E%A5/"><span class="post-readmore__text">阅读全文</span><span class="post-readmore__icon"><i class="fas fa-long-arrow-alt-right"></i></span></a></div></div></article><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/2023/01/01/SE/">Squeeze-and-Excitation Networks-</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">发表于</span><span class="post-meta-item__value">2023-01-01</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">更新于</span><span class="post-meta-item__value">2023-06-20</span></span></div></header><div class="post-body"><div class="post-excerpt"><h1 id="摘要"   >
          <a href="#摘要" class="heading-link"><i class="fas fa-link"></i></a><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1>
      <p>  卷积操作：<br>  卷积操作是卷积神经网络(CNNs)的核心构造块，它通过融合每一层局部接受域（感受野）内的空间和信道信息使网络构建信息特征。大量先前的研究已经调查了这种关系的空间成分，试图通过在其特征层次中提高空间编码的质量来提升CNN的表征能力。</p></div><div class="post-readmore"><a class="post-readmore__link" href="/2023/01/01/SE/"><span class="post-readmore__text">阅读全文</span><span class="post-readmore__icon"><i class="fas fa-long-arrow-alt-right"></i></span></a></div></div></article></section><nav class="paginator"><div class="paginator-inner"><span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/2/"><i class="fas fa-angle-right"></i></a></div></nav></div></div><div class="sidebar-wrap" id="sidebar-wrap"><aside class="sidebar" id="sidebar"><section class="sidebar-toc hide"></section><!-- ov = overview--><section class="sidebar-ov"><div class="sidebar-ov-author"><div class="sidebar-ov-author__avatar"><img class="sidebar-ov-author__avatar_img" src="/assets/tx.jpg" alt="avatar"></div><p class="sidebar-ov-author__text">漏勺的加油站</p></div><div class="sidebar-ov-state"><a class="sidebar-ov-state-item sidebar-ov-state-item--posts" href="/archives/"><div class="sidebar-ov-state-item__count">28</div><div class="sidebar-ov-state-item__name">归档</div></a><a class="sidebar-ov-state-item sidebar-ov-state-item--categories" href="/categories/"><div class="sidebar-ov-state-item__count">11</div><div class="sidebar-ov-state-item__name">分类</div></a><a class="sidebar-ov-state-item sidebar-ov-state-item--tags" href="/tags/"><div class="sidebar-ov-state-item__count">7</div><div class="sidebar-ov-state-item__name">标签</div></a></div><div class="sidebar-ov-cc"><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en" target="_blank" rel="noopener" data-popover="知识共享许可协议" data-popover-pos="up"><img src="/images/cc-by-nc-sa.svg"></a></div></section></aside></div><div class="clearfix"></div></div></main><footer class="footer" id="footer"><div class="footer-inner"><div><span>Copyright © 2023</span><span class="footer__icon"><i class="fas fa-heart"></i></span><span>小勺</span></div></div></footer><div class="loading-bar" id="loading-bar"><div class="loading-bar__progress"></div></div><div class="back2top" id="back2top"><span class="back2top__icon"><i class="fas fa-rocket"></i></span></div></div><script src="https://cdn.jsdelivr.net/npm/jquery@v3.4.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.2/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.2/velocity.ui.min.js"></script><script src="/js/utils.js?v=2.8.0"></script><script src="/js/stun-boot.js?v=2.8.0"></script><script src="/js/scroll.js?v=2.8.0"></script><script src="/js/header.js?v=2.8.0"></script><script src="/js/sidebar.js?v=2.8.0"></script><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"live2d-widget-model-miku"},"display":{"position":"left","width":150,"height":190,"hOffset":50,"vOffset":-5},"mobile":{"show":false,"scale":0.5},"react":{"opacityDefault":0.7,"opacityOnHover":0.8},"log":false});</script></body></html>